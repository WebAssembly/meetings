![WASI logo](https://raw.githubusercontent.com/WebAssembly/WASI/main/assets/WASI.png)

## Agenda: July 10 WASI video call

- **Where**: zoom.us (see Registration below)
- **When**: July 10 2025, 17:00-18:00 UTC
- **Contact**:
  - Name: Yosh Wuyts and Bailey Hayes
  - Email: wasm@yosh.is and bailey@cosmonic.com

### Registration

The meeting is open to CG members only. You can [join the CG here](https://www.w3.org/community/webassembly/).

If this is your first time attending, please [fill out the registration form](https://docs.google.com/forms/d/e/1FAIpQLSdpO6Lp2L_dZ2_oiDgzjKx7pb7s2YYHjeSIyfHWZZGSKoZKWQ/viewform?usp=sf_link) to receive an invite. Please make sure you have joined the CG as above, and that your name appears on the [membership page](https://www.w3.org/community/webassembly/participants), before registering.


## Logistics

The meeting will be on a zoom.us video conference.

## Agenda items

1. Opening, welcome and roll call
    1. Please help add your name to the meeting notes.
    1. Please help take notes.
    1. Thanks!
1. Announcements
    1. _Submit a PR to add your announcement here_
1. Proposals and discussions
    1. wasi-gfx update (Mendy Berger)
    1. P3 Jco implementation update (Victor)

## Notes

### Attendees

- Bailey Hayes
- Dan Gohman
- Jeff Charles
- Mendy Berger
- Sean Isom
- Victor Adossi
- Yosh Wuyts
- Luke Wagner
- Pat Hickey
- Chris Woods
- Alex Crichton
- Chris Suszynski
- Colin Murphy
- Andrew Brown
- Jeff Charles
- Stephen Berard
- Chris Suszynski
- Michael Sanchez

### wasi-gfx update (Mendy Berger)

**Mendy**: Quick update, since we have been very quiet over the past couple months. Doing work, but time for an update. 

**Mendy**: Most of the work in wasi-surface and wasi-webgpu. We haven’t moved to stabilize wasi-webgpu until WebGPU v1.0 and also may wait for WASIP3. In terms of implementation status, we have this with wasmtime at github.com/wasi-gfx/wasi-gfx-runtime. We also plan to implement this in WasmEdge as soon as they have Wasm components support.

**Mendy**: Browser Shim at github.com/wasi-gfx/wasi-gfx-shim

We have a playground at wasi-grfx.github.io/playground.

There are rust libraries, wgpu with wasi:webgpu, as well as JS with WebGPU JS spec support. 

C/C++ is not ready yet.

On to wasi-surface. We’re rebasing surface to be closer to what JS has like PointerEvents and KeyboardEvents. We don’t yet have support to move forward for stabilization. We’re keeping in phase 2 as we iterate. Hoping to get consensus as we move forward.

**Luke Wagner**: The simplest case for WASI is when we take a de facto standard and WIT-ifying it. This is the case for WebGPU and is where concepts are well understood. When it comes to UI, even when setting aside widgety things, as an example you can look at SDL as a widespread abstraction, it has a ton of stuff in it. It’s a big thing. One option would be to WIT-ify SDL. SDL is already part of emscripten’s portability story. This is a very big design space and there is a lot going on when trying to abstract over other inputs and UI.

It doesn’t just stop at Pointer and Keyboard events. It’s not to say we shouldn’t do this, but need to do more collaboration before stamping it. Moving at a different speed for surface than webgpu.

Bailey: Could you explain your choices behind wasi-surface?

Mendy: We wanted to take more things from Canvas, and in general assume that the Web did the right thing, or that it will work well enough. So far, what we’re using from it is fairly small. You can create a surface, it has a size, and you can subscribe to events.

Bailey: In terms of what you’re Witifying from the Web, what APIs are you covering?

Mendy: Primarily keyboard and touch events

Bailey: Specifically, the challenge is, which industry standard do we follow. Stating the goals of wasi-gfx would be apropos here.

Mendy: We’re developing 4 things. First, wasi-webgpu; wit-ifying webgpu. But WebGPU doesn’t have a way to connect to a screen. On the Web we’d use Canvas, so for WASI we need something similar, and that’s wasi-surface. So wasi-surface is all about events and anything that’s displaying to the screen that isn’t webgpu. Based on feedback from Luke and others, we’ve refactored these APIs so that different graphics APIs could be connected and have their own worlds.

Bailey: Ok so wasi-webgpu maps 1:1 with WebGPU. Then there’s wasi-surface, where you’ve got events, pointer events, keyboard events, and then there’s the aspect of what is the window and how do I draw to it. SDL seemed promising, though one of the challenges is that it’s big.

Mendy: SDL is not only big, but it overlaps with a lot of other WASI APIs. So we maybe take a subset of it, but if we’re doing subsets, maybe we should do a subset of the Web.

Sean: Over time, there should be an SDL implementation that runs on the Web, but we don’t want to obliged apps to refactor to use SDL just to use wasi-webgpu.

Bailey: Surface is unstable, there’s iteration, and you need feedback. So the question here is, is rebasing wasi-surface on Canvas sufficient for it to move forward as a WASI proposal?

Mendy: Yes.

Bailey: If the motivation for the proposal is to make it easy to port WebGPU applications, aligning with the Web standards makes a ton of sense. I’m concerned that this would require too much to be brought over. And there’s a lot there that we’d want to reuse in other use cases, which would be a lot to take on, but overall, my feeling is that’s generally the right direction.

Colin: Could we talk about how WebGPU would be broken down?

Sean: Analogy: wasi-webgpu is the WebGPU spec. Wasi-surface is your Canvas, or more broadly, your OpenGL context.

Luke: We don’t want The DOM writ large, because it is large, but it’s not clear where we could draw a boundary that just includes Canvas and anything needed by applications without pulling in the whole DOM.

Mendy: I think the answer is not clear. WebGPU itself makes assumptions that it’s running in a browser, using DOM and JS.

Colin: Can we look at the practical use cases? Can those align with anything that we can use to draw a boundary?

Sean: I want to hear from Yosh. There are different classes of app integrations with the web. There are three use-cases, first is the headless AI inference class using GPU but not attached to a UI. Number 2, attached to a canvas as a full screen application, could also be used for server-side rendering. The last is the rich web application. As it is today, this covers the AI use-case well. We aimed to support more of the full use-case for first and second types of apps. Most apps that use webgpu on the web, it’s the third case, the rich app case. This is much more of an open question.

Yosh: When we talk about portability, what do we mean by that? Because we’re saying we want "portable apps”, but there are a lot of meanings to that. Such as version 4 on the slides here where you don’t have any JS and are drawing to a full screen.

Mendy: Replaces electron.

Colin: I don’t know if server-side rendering is a full wasm app. Third case is like photoshop. We do have use-cases where we have to do a lot of different video qualities, has to be transcoded in different video qualities. I don’t know if that really is a full use of canvas, we call that server-side rendering but I don’t know if that fits neatly into those 3. So maybe a transcoding use-case.

Sean: I don’t know enough about this use-case but should note that as a very important use-case.

Mendy: Depending on the implementation, we might not need wasi-surface at all; wasi-webgpu might be sufficient.

Bailey: To have confidence in Canvas, we want to see that you can do that successfully without having to mirror the whole DOM.

Mendy: Yes, I feel like that needs to happen. We don’t have that yet. If we are able to do this,that would perhaps allow us to progress wasi-surface.

Yosh: Have you reached out to the WebGPU spec authors? Are you contact with them?

Mendy: Yes, we may also attend their in person meeting. GPU is a little different from the UI side.

Victor: What would be the best place for someone to enter and use the wasi-gfx to use right now?

Mendy: In the wasi-gfx org, also one here MendyBerger/wasi-gfx-examples.

Sean (in chat): https://github.com/wasi-gfx/wgpu/tree/windowing-support/examples-wasi

Victor: Will you add these to the top-level repo to make it easier to find?

Mendy: I’ll do that.

### P3 Jco implementation update (Victor)

**Victor**: JCO: Until last week, my work on JCO was working on basic operations and giving things reasonable implementations. So now this week, I’m in a stabilization phase. I’m finding it difficult to implement individual features, because they tend to pull in other features.

Here’s an example of a P3 component that just uses context.get/context.set, and it’s using it a stackless coroutine way, callback driven. In JCO, the component transpiles and loads, but doesn’t quite do the right thing yet. So I’m now going through and making sure that all the behaviors are correct.

Testing by pulling in P3 WASI interfaces, pulling in the wast component tests, and running JCO-specific tests.

**Bailey (in chat): For context, JCO is the second reference implementation taking WASI specs and running them in the Node.js runtime

Bailey: Any call to actions?

Victor: Not right now, I think the tests are relatively thorough, so I just need to go through them. I haven’t run into anything in the spec that was too confusing to implement, so that’s good. Luke has been helpful answering questions. So I don’t have any blockers right now.

Bailey: You did mention that there is some drift between what’s in the P3 proposal and the [...]. Looking for feedback on how we should do releases. We’ve been doing 0.2.x releases for 12 months, so it’s a good time for feedback. Feedback specifically requested on WebAssembly/WASI#659.

Victor: In retrospect, it would have been easier if P3 could have been broken into smaller pieces, that would have made it a lot easier to implement. For example, we have tasks, and that plus context.get/context.set could have been introduced as an incremental change to P2. But that’s just an observation. Everything is clearer with 20/20 hindsight.

Victor (in chat): also, everything is clearer with 20/20 hindsight
