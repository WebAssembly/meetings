![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the October 3 video call of WebAssembly's Garbage Collection Subgroup

- **Where**: zoom.us
- **When**: October 3, 4pm-5pm UTC (October 3, 9am-10am Pacific Time)
- **Location**: *link on calendar invite*

### Registration

None required if you've attended before. Fill out the form here to sign up if
it's your first time: https://forms.gle/JehrAB4gWbtHjybt9. The meeting is open
to CG members only.

## Logistics

The meeting will be on a zoom.us video conference.
Installation is required, see the calendar invite.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking (acting chair to volunteer)
1. Adoption of the agenda
1. Proposals and discussions
    1. Resolve text format final/open/??? issue ([#423](https://github.com/WebAssembly/gc/pull/423))
    2. Renaming extern conversions ([#432](https://github.com/WebAssembly/gc/issues/432))
    3. Discussion of follow-on GC proposals
1. Closure

## Meeting Notes

### Introduction of attendees

- Thomas Lively
- Zalim Bashorov
- Alon Zakai
- Ben Titzer
- Nick Fitzgerald
- Manos Koukoutos
- Ilya Rezvov
- Adam Klein
- Ashley Nelson
- Sergey Rubanov

### Resolve text format final/open/??? issue

TL: We have a slot at the in-person for new GC proposals, but it would be helpful to discuss here first. RH & AR aren’t here, so we may not be able to resolve the text format issue. Let’s just review the state. The latest discussion on the final open close text format, is that RH discussed it with Mozilla folks and they don’t think AR’s last proposal fixes things, but they don’t want to continue discussing it either. So maybe we’ll go with AR’s thing. Close that discussion when AR is around.

AK: Maybe it’s something we can resolve in-person in 10 minutes with the right parties. Not a fan of adding extra to the text format.

TL: Do you know if RH is going to be in-person?

AK: He is.

TL: Great, let’s plan to grab RH & AR and hash this out in-person

### Renaming extern conversions

TL: I think this is a good idea. We don’t have an immediate use case but I think making more future proof makes sense, just a text format change. Any other opinions/objections, anything to say?

TL: If no opinions, we can accept this change and close this asap so everyone can go implement.

### Discussion of follow-on GC proposals

TL: First, I have a combination follow-on proposal for GC and EH, even though EH isn’t done yet. It’s a proposal to add throw invariants of trapping instructions. So struct.get and the reference is null, that would trap. For Java, that would result in a null pointer exception instead. Could add explicit guards around all of your struct.gets to check for null but that has a huge amount of code size and perf overhead. We’d like to fix that. I have an explainer for the follow-on proposal almost ready to go. Just need some hard data about the code size before publishing.

TL: The other proposal is shared wasmGC, so multithreaded. We have a basic design for this ready to go because it was published in an appendix of a paper on the linear wasm model that AR and CW and a few others wrote back in 2018. So we have a really great starting point but there are a lot of details to figure out about what kind of atomicity we’re going to provide for references to share in reference type fields. We can’t allow out of thin air behavior for shared reference type fields, that would be bad from a security perspective. How do you properly compile OCaml to WasmGC? Lots of work to do there to figure out those details. Slightly esoteric memory model work. What we are going to impl, what are people going to use? How do we spec it and make it safe? Hoping to make progress on it the rest of the year, hopefully having something people can play around with early next year.

TL: Any other post-MVP wasmGC proposals?

ZB: Question about traps, is it only about nulls for struct.get or something more widely.

TL: What I have in mind is broader than null checking, we’ll have the initial proposal to be discussed in the community, throwing variants of division and remainder operations, and then all of the struct and array accessors. For array accessors, we’ll have throwing for the null check and the index out of bounds check, so that you can raise different exceptions depending on the reason for the error.

ZB: Great, had the same request for Kotlin.

TL: I think it’ll be useful for a lot of people. Not including throwing variants of every single trap instructions, for example memory loads and stores we won’t have throwing variants of because those are used by low level variants of C and C++ where itw as undefined behavior for OOB memory access. But 

ZB: In my mind, catching any trap except unreachable makes sense

TL: I agree it would be nice and symmetrical, but my worry is we’d have a lot of instructions nobody would use in practice. Array.copy has 4 different reasons it can trap, 2 ararys, and each of them could be null or OOB. So if we add that instruction in the proposal, it would take 4 tag immediates and be expensive/heavyweight. We’ll definitely discuss. Expect it to be a common thing of people asking for all the throwing variants, which is a reasonable ask, but we have to see if its worth it.

ZB: In general, Kotlin worries about size. Trying to work on things that improve size, nothing specific right now.

TL: Good to know.

ZB: It would be nice for array.new_elem and array.new_data to be const instructions. We have to initialize some constants lazily and these lazy things take some space in the binary and it’s not cheap at runtime. Another thing not directly related to GC is there are runtime bool checks to make sure an object is initialized before accessing, and it would be nice to have some way to only check once. Right now we do it with explicit checks so its not fast at runtime. Would be nice to have machine code that after the first access check, optimizes the call.

TL: Some type of monotonic initialization that notices things won’t change and optimizes?

ZB: Yes

TL: Java folks need that too for class initializers. We can look into what we can do there. 

BT (via chat): Another option for throwing versions of trapping instructions could be to have a section that defines trap handlers per trap type; I’m somewhat worried about the explosion of instruction variants. That makes handling traps per-module but factors out all the trap handling logic

TL: That could work BT. Has some downsides but we can wait till we have a full explainer so we can file issues and have a full discussion. There is a wide design space here and the initial thing I plan to propose is certainly not the only way to achieve the goals. 

ZB: One more thing not about GC is we need something to manage new features in the future. We want to generate binary, how we can introduce new features from Wasm to specific toolchain like Kotlin-Wasm, how can we introduce smoothly without breaking things on user side. We need some sort of feature checks, to see which features are available. In some cases we can switch to different functions but at least we need to have the ability to say to users what doesn’t work and why it doesn’t work. We need something more robust than our basic feature checks. When we fix from old GC instructions to final version, we don’t have any way to say at runtime what browser we’re trying to run. We can’t give the user advice that you’re using an old browser, try to update your browser. Or your browser didn’t support it at all.

TL: This request comes up a lot. It would be nice to have something in the spec section. The state of the art is to use tiny wasm modules that uses features with wasm.validate to see if the features are available. Use tiny wasmGC module and run validate on that.

ZB: If a user comes from outside of Chrome and doesn’t support final version on default, old browsers don’t support it at all. We need to suggest turn on and use some old binaries.

TL: I see, you can’t tell the difference of whether it’s an old browser with no support or one where the support isn’t turned on by default. Good feedback and feature detection keeps coming up. We had a proposal for feature detection in Wasm. It probably wouldn’t have worked for this particular use case because they were more about hot functions they wanted to include different versions of in their binary and changing the opcodes changes the entire binaries, so you’d need a more robust API for features like Javascript to detect that. It’s come up before but we haven’t proposed anything. I know AR next week is going to talk about his vision for different Wasm profiles, different feature sets. Not sure. Good problem to think about, thanks for bringing it up.

BT: Working on type imports is going to be important, probably the next most important after GC. 

TL: For ecosystem concerns? Useful to import types or string use case or? What use cases?

BT: Yeah, I think APIs are going to start appearing that are more than just externref and can be implemented with WasmGC and you want to import types from APIs and export types from your module. I think it’s the key to unlocking ecosystem evolution. Something we should work on. From my side, I had given a talk a year ago about combining header information so there is a header for every WasmGC object. And there is a field in it for every meta state. So having a meta field can save a bit of space. Fundamentally comes down to improving the memory usage of WasmGC objects.

TL: IIRC, would allow defining static fields on the meta object that would go on the type rather than on each instance of the class. 

BT: That’s what AR had proposed, I think it needs to be more general than that. One field with the meta object field which is a default that points to a canonical RTT. A field that is mutable but that thing is an object you control the layout of. Not just adding fields to one global meta object per type, but a different meta object per type. Different meta objects are fine with the latter.

TL: That’s just strictly more general and would allow static fields, right?

BT: Right

TL: Could be exciting. Intrigued by being able to replace the meta object. Not sure our toolchain partners have a specific use case for that, but more powerful primitives are nice. We are excited about adding static fields for vtables to reduce the size of meta objects, so something in this space would be great. Are you planning to revive this discussion and make a proposal in this space?

BT: Yes, planning to talk to AR about this next week.

TL: Great.

ZB: import could be helpful in case of module splitting (generating many modules instead of one). Merging modules together is not easy because if you start generating a few modules, you need to do a type check somehow. You need to put types together in a recursion group to use built-in type checks. Otherwise you have to invent your own type checks. In general, we need something to simpify the cases when we generate a few modules together, not one monolithic module, and they will be each run.

TL: Makes sense, a thing in Binaryen we’ve thought about. Optimize the module and put all the types in a giant recursion group to keep it simple. We’ve thought about making a pass that would break the giant group into multiple small groups, as small as possible. Bundle all of your stuff together, optimize your module and run this pass to get the small recursion groups, and then each split up module would have the small recursion groups it needs. Only works if you bundle into one big module at first and then split it back up. Not going to work as well if you are going to create separate modules and keep them separate and you never get that global view of all the types.

ZB: Generating several modules on our side might be important to avoid running other tools during development. We want to develop binaries incrementally. Doing the same thing would require additional work on our side. In development mode, we don’t want to run any external binaries, like Binaryen or any other tool, but in release builds we have to run additional optimizers.

TL: Right now, if you want to generate separate binaries, you can generate your own small recursion groups, but I don’t know how you’d get away without having your own user level type checks to avoid when they get merged. It would be nice if type imports allowed you to get away without those type checks. Or BT’s idea to swap out the meta object allowed you to do that. That’s definitely something we can think of. Not the only one to raise this question. The Java folks have also been thinking about separate compilation. That will be a common use case that is not super well addressed right that. 

AZ (via chat): Another post-MVP feature that could be useful is weak references / finalization. Helpful in particular for combining GC with linear memory (to know when to free in linear memory).

ZB: Right now we use javascript API for weak references, so we need it for caching things. If we had something built-in to Wasm, it would reduce our dependency on JS.

TL: Are you trying to target off-web use cases?

ZB: Not only about a dependency on JS, when we want to cache anything, right now we have to have code in JS and this code is not super cheap. When you do it often. We probably need something out of browser as well. We don’t have a way to do caching.

TL: We could add finalization as a core wasm feature. A lot of people would want, benefit. A slightly simpler way to solve the problem would be to create an importable API from JS for finalization registry so that the calls are super fast, just like we’re doing with strings. That would solve performance and let us get away without having finalization to core Wasm. But for the off-browser use case, producers would need to be sure that the engines provide the API as well. I'm not sure what core Wasm finalization would look like.

ZB: Another direction is, for example we get a parameter and it’s usually anyref and we have to cast it to the method receiver type. Another problem with interface calls is it takes about 7 operations/instructions for a class virtual call about 5 operations. Much slower for us. 

TL: Yes, virtual calls are slow

ZB: Virtual calls today where we can try to improve on our side. Improvements on Binaryen side can halp. VM side.

TL: Certainly we can make devirtualization better in Binaryen a lot better. We’ve put a lot of effort in here because it has such huge performance benefits. We’ll continue improving where we can. For the cast, the receiver cast on virtual method calls, where you have to downcast the receiving object has come up a lot. Two approaches we can take, one is to add a notion of methods into core Wasm, just like Java, so that Wasm would know a downcast is always going to succeed and not have to do anything at runtime. That would be a high level approach. The other is to improve the type system so we can more generally express, using low-level type system, that this downcast will always succeed. I think this is more complex and would require an advanced type system and an area of research, but if we could pull it off, that would be great because low-level primitives are generally more useful.

ZB: Right now we work around it by putting in the start of every function, casting to a local. Insert the local with the right type. 

TL: Yup, that should work. Would be interesting to identify more opps in Binaryen to remove those casts as well. Normally we devirtualize and then you can remove the cast. But maybe we can remove the cast in some places without even fully devirtualizing. Both in the tools and the spec, this is an interesting area to work in.

ZB: Another direction, JS and browser APIs interop. For performance. On JS side, have functions that expect a context object. You can’t import directly such a function because there are no such things in Wasm. Maybe it would be nice to have such imports directly. A lot of work in object model, how your modeling can enable access directly from JS side.

TL: Is your usecase for mapping the objects to each other, people writing handwritten JS that is interacting with the JS modules that are passing back and forth. And you want an ergonomic experience of writing this JS code?

ZB: Yes, would also like to be able to do everything we can’t do with JS right now. Writing web components with Wasm without any JS involvement if we’re speaking about long term. But we need specific steps to go in this direction incrementally.

TL: Long term, every web API is importable into Wasm and then you don’t need to write any JS, but until then, you have to wrap these Web APIs you want to import into your Wasm module and you need to make the process of writing those importable libraries as ergonomic as possible and not worry about interop on the border. Do you know about the shared structs JS proposal that is adding. The idea is that the proposal would interoperate with WasmGC and that’s been the idea but we don’t know how the details are going to work. Going to sync with Shu-yu Guo the champion of that proposal in a couple of weeks and we’ll figure out the details of the interop story.

ZB: Speaking of browser APIs, would like to improve APIs for WebGPU where we need to pass arrays and strings. Would be helpful to pass WasmGC arrays directly to these APIs, right now we have to copy to buffer. Would also be useful to have more instructions to work with WasmGC arrays. You have i42 array but sometimes you need one byte and vice-versa. 

TL: Arbitrary loads and stores on byte arrays. That would be good as well. Thinking about WebGPU use cases you mentioned. Type imports might help there because you can import types from these APIs and manage them as separate types instead of lumping them all together as externref would be helpful in code correctness and performance because fewer type checks. The problem of using Wasm arrays directly instead of copying them to JS buffers, that would be nice a superpower, probably tricky on the implementation side.
