![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the February 7 video call of WebAssembly's Garbage Collection Subgroup

- **Where**: zoom.us
- **When**: February 7, 5pm-6pm UTC (February 7, 9am-11am Pacific Time)
- **Location**: *link on calendar invite*

### Registration

None required if you've attended before. Fill out the form here to sign up if
it's your first time: https://forms.gle/JehrAB4gWbtHjybt9. The meeting is open
to CG members only.

## Logistics

The meeting will be on a zoom.us video conference.
Installation is required, see the calendar invite.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking (acting chair to volunteer)
1. Adoption of the agenda
1. Proposals and discussions
    1. Discussion: Consistent rationale for type annotations ([#324](https://github.com/WebAssembly/gc/issues/342))
1. Closure

## Meeting Notes

### Introduction of attendees

- Thomas Lively
- Slava Kuzmich
- Conrad Watt
- Asumu Takikawa
- Luke Wagner
- Andreas Rossberg
- Adam Klein
- Alon Zakai
- Ashley Nelson
- Manos Koukoutos
- Francis McCabe
- Ryan Hunt
- Matthias Liedtke
- Zalim Bashorov
- Igor Iakovlev
- Ilya Rezvov
- Deepti Gandluri
- Jakob Kummerow
- Ben Titzer

### Discussion: Consistent rationale for type annotations ([#342](https://github.com/WebAssembly/gc/issues/342))

TL: To recap, we are continuing a discussion about type annotations. Everyone agrees that we should have a consistent method for figuring out which instructions have type annotations. The question is, what method should that be? And what’s the motivation for that? I’ve talked with colleagues on the v8 team and we agree that a consistent method here would be great. Our preference is to simply remove the type annotations, it would avoid a bunch of these tough questions and be good for code size. And any tool that needs types can recover them with a single pass due to our validation design constraints. Andreas I saw you respond to that. Can you summarize?

AR: Three options at this point: 1) reverse decision we made last time, and remove all the annotations. 2) ignore what we decided last time and don't do annotations this time. 3) add these annotations on cast instructions. (1) seems like reopening a long and painful discussion, and if we reversed that we'd open a couple of issues we'd closed (e.g. unreachable code). (2) feels bad to me since we have to ignore the reasons we decided to add the annotations last time. (3) isn't ideal, but seems the least-bad to me. It's a bit more cost added to the cost we've already agreed to.

TL: For the path of just biting the bullet and just adding the annotations as you put it. If we can arrive at something consistent, then great, I would be glad to close this discussion. My concern is that we don’t have a consistent rationale that backs up our choices of what to annotate. Last week we talked a lot about principal types so I took a look at the instruction set and saw that if we actually want a principal type for each instruction, there are a bunch of annotations we want to add. So existing polymorphic stuff wouldn’t fit the rationale.

AR: To be more precise on what it means to have a principal type: you can express polymorphism with an unconstrained type variable. In the case of drop, you can put in any type there, there's no additional constraint. What's different for these other instructions is that you have some kind of variable, as well as a constraint on the side, it cannot be arbitrary. For accessors, you have to deal with the n-th field of some structure, and it has to be a subtype of something-or-other, and this makes a qualitative difference. It's something like the difference between type inference, and type inference in the presence of subtyping. (restated version of [this comment](https://github.com/WebAssembly/gc/issues/342#issuecomment-1420748058))

TL: In general, sure, absolutely. Specifically for Wasm, I have a hard time seeing that it matters, the difference between principal types up to unconstrained type variables, and principal types up to, you have to do more inference for each instruction. But it’s all linear anyway, so what’s the difference?

AR: Not just that you can do something linear, and solve the problem. The more general problem is you want to know for certain optimizations, when you do code refactorings, like constant propagation or subexpression elimination or whatever the corollary is in Wasm. It’s not sufficient to know the type of something in that specific context. You actually want to know the most general type you can assign to it, that might influence how much you can reuse that part. So how general this sequence of code is you are thinking of here and if you can outline that and call it from different places or the other way around, you can inline it. Inlining you are actually duplicating, so that doesn't matter. 

TL: For outlining, you are giving it a concrete signature type so it doesn’t matter, you have to instantiate variables.

AR: Basically when you arrive with type variables. We might have polymorphism or generics at some point, that aside it basically means you don’t have to care in some of these use cases if there is a type variable remaining. You can just put in whatever you want because all the use cases don’t care potentially. Whereas with the others, you still have to deal with all these constraints on the side. These use cases in terms of practical use cases may seem hypothetical but having talked with static analysis folks, it’s something they care about, keeping this analysis. I think I mentioned that last time, one thing they repeatedly told me last time is they were glad we didn't do overloading, which is like a simple version of this problem. And now we're discussing a more complex version of this same thing. 

JK (chat): Is anyone going to do such analyses/transformations on the Wasm instruction level? Wouldn't any serious tool use its own custom IR anyway?

AR: That depends on what your tool is trying to do. If it’s on the Wasm level, then sure it will use the Wasm instruction set. If you want to transform Wasm to Wasm somehow, for whatever reason, then why.

TL: To give a concrete example, Binaryen does nothing but translate Wasm to Wasm and it kind of has its own IR but really tries to reuse Wasm as much as possible and it’s very deliberate about where it departs from Wasm in its IR and one of those places is it deliberately discards all of these type annotations because it would rather not have those extra type constraints. It wants to discard the type annotations so it can deliberately recover the most specific type.

AR: It’s a common pattern with typed IRs, where you have to produce something typed, that throwing out the type info in the middle is something you might regret because you might need the type IR later. 

TL: And we certainly do require type information but we recover it with a linear pass whenever we need it. There is a very concrete example of a producer doing this Wasm to Wasm translation that we’re talking about and that producer does not want the type annotations.

AR: It is unfortunate that we don’t have the folks doing this kind of thing to explain their situation. I can only relay what I’ve heard in speaking with people like that. 

TL: Anyone else like to chime in here?

AK: I want to raise binary size, it sounds like we’re getting some interesting constraints here in wasm. On one hand, a compact format for transmitting optimized apps over networks. On the other hand, we’re trying to use it as an ideal IR for programming transformations and those sound like different domains to me. I think we could benefit from working out a framework for deciding what the priorities of constituencies are. There are lots of different ways to consume Wasm, it seems tricky to pit these things against each other. 

AR: It’s a fair point. It’s definitely the case that WebAssembly isn’t designed to be an IR itself. IIRC that was an explicit non-goal in the beginning. LLVM for example would make different choices w.r.t space and things like that. That being said, for most static analyses you don’t want to have to convert the program to an IR first. I have experience in this field and I know how easy it is to make things hard due to sloppiness.

TL: It’s not sloppiness for sloppiness sake, it’s to save bytes on the wire.

LW: I have a question, is this overloading we’re talking about? Overloading if i understand right is the type context I’m in changes the context. Polymorphism is we do the same thing regardless of the type. Overloading is polymorphism is about subtype bounds?

AR: You’re right, overloading is a slightly different thing with an operational meaning. Overloading means this additional thing.

LW: Potentially our type analysis should be more complex.

AR: I think we didn’t want overloading for the reason you’re saying, we view it as a different operation. But it turns out this is a good thing to avoid for another reason, because it makes the type analysis level more easy. And with respect to that, it is in the exact same class as the thing we’re discussing now. I’m feeling a bit uncomfortable because Ben isn’t here and he was a particular vocal proponent of having type annotations. So what are we going to do? We are discussing reversing the decision wouldn’t be fair without Ben here.

TL: Agree, but I think there is space to understand the options and get on the same page. For option 3, add more type annotations, I’m concerned. How confident are we that we haven’t broken this with our existing standardized Wasm? Will we find that oops this standardized instruction doesn’t fit with the type annotation? Will we be able to explain this rationale to anyone else? I think explainability is important for rationale. Why do I have to send all these extra bytes over the wire? I should be able to explain why it was important. Perhaps offline, it would be good to have the crispest possible statement of this design rationale and double check we haven’t violated it somewhere else, double check it explains all the annotation choices we’ve already made. And even then, how explainable will it be?

AR: When I wrote the spec, we did this appendix for properties and that basically contains type soundness and I called it properties because there are other properties that might be interesting. Which would have been the version of principal types. But I’m saying this is something you can formulate precisely and not something difficult to prove, just induction on the type. And for most of the rules, it’s completely obvious that it holds so I’m happy trying to do that. And then the way you could think of how to phrase this formal statement in layman’s terms is for every instruction you can give basically a type that is in closed form that describes what the type is with some type errors. But that’s all you need, you don’t need conditions on the side. That’s the type of type property I would accept here.

TL: Curious to hear from other folks who haven’t spoken up yet. 

CW: I have a preference for adding the type annotations. I definitely believe there is a world in the future where we can come up with the variants of the structure without the type annotations. I think there is also a distinction between br_on_null/br_on_non_null and on_cast instructions. Which is br_on_non-null is not trying to be polymorphic on and you know the input is not null, you can refine the type a lot more. There’s no point in emitting the instruction.

AR: If we have the type annotations the typing rule becomes more simple, even simpler than the discussion I wrote. I realized after that you can get rid of the common top-type? If you have a top-type, you only need to know one is the subtype of the other. So this fairly complex condition Conrad worked out for propagating nullness would go away. And I’m scared of that condition because it has 8 or 10 different cases and shouldn’t be that complex. There would be just one subtyping check and that’s it.

TL: I admit this would be a great outcome.

~ Ben Titzer joins ~

TL: Hi Ben, you came up before when AR mentioned that removing the type annotations would be uncomfortable without you here. Most of the discussion hasn’t been about removing, it’s been about rationalizing adding more type annotations. Do you have new thoughts on the subject you’d like to share?

BT: For me it’s not about in-place interpreters, it can use side table entries and probably will for speed anyway particularly for struct.get. But for baseline compilation it does not model the complete types, only kinds are necessary so if we remove the type annotations then it would be necessary to model all the complete types in the baseline compiler And one point I made about keeping the type annotations is for other tools that process bytecode, static analysis tool that doesn’t necessarily want to completely replicate the type annotation algorithm. They all benefit from type annotations. Just repeating and reminding folks of my points.

TL: Possible way forward. We could give AR an AI to write a crisply stated design rationale offline and make sure we haven’t violated it so far. Then we could add new type annotations in accordance with that rationale. After due diligence, we could add the annotations and settle this. Right now, that’s looking like the least path of resistance to get this resolved. Would anyone prefer a different course of action besides everyone who would like to remove the type annotations for code size reasons?

AR: I should add this is the most conservative, because we can always remove type annotations for code size reasons, but adding will not be possible, ever.

FM (chat): This seems like a case for having a criterion: what is more important: wire size or making life easy for generators

TL: This gets back to what Adam was saying, we have a bunch of different communities of Wasm who have different design priorities and it would be helpful to come up with a framework to navigate that. That being said, in this particular case, despite the wire size concerns, it is true that this does seem like the more conservative choice. We could also add unannotated versions in the future like Conrad said.

AK (chat): Some prior art on criteria from the w3c: https://www.w3.org/TR/design-principles/#priority-of-constituencies

BT: For the input type to cast, if we moved to Any as the input type and didn’t require the validator to reject invalid casts. Would that solve the problem? So impossible casts, like a cross type, where the input type is not a supertype of the casted to type

AR: One thing we noticed is that there is a similar problem with nullability, not just the heap type involved. So that also means we need to annotate on that otherwise we lose this kind of principality I think..

CW: You could save a byte if you have a hardcoded case from Any. I need to think about if that works because you could have a bit free to say if you were nullable or not.

AR: Yeah, so basically you need to know it’s true that it would be enough to say what is your top type, currently we only have three. But it’s not clear that it stays that way. If we do what Ben just suggested, what would that imply? I need to think about that, it might work.

CW: I think it would still be a problem with br_on casts. I need to think this through.

AR: They would just be unrelated right? Means you can’t take that one path. I don’t think it causes a problem but we need to think about it more carefully. In that case we would need only the null annotation for that.

CW: (note taker missed this)

AR: If we don’t need the top type then we could roll the instruction into the opcode itself.

BT:  I think you can figure out the top type from the annotation.

CW: You can but the proposal was not to need the annotation in some circumstances, right?

TL: The cast annotation, the one that tells you what the cast is supposed to do 

AR: It doesn't work to use the top type there, the reason is the br_on_casts. If you do the top type, then you lose the type information on the top type so that doesn’t work. You want a precise type there so it doesn’t work. So that the thing remains on the stack and you want it to be precise. So it’s not good enough to have a top type. 

TL: Anyone have objections to continuing to resolve this offline with a tentative goal of coming up with a rationale and adding the extra annotations? Okay, then that’s what we should do and let’s plan to have this resolved before the next meeting. AR, please take up the AI to have a precise rationale in the issue and we can all take a look at it.

AR: Sure, I’ll try to do that.

TL: No other agenda options, but an update on bulk_array stuff… 

### Bulk Array operations

TL: I checked with Dart and J2CL (Java) for partners and it sounds like everyone is happy for now with the minimal set of instructions, so I guess it would be helpful to clear with you all what that minimal set of instructions should be: array.copy, array.fill, and the question I have is would folks be unhappy or consider this an insufficient set of instructions if we skipped array.init_data and array.init_elem. The rationale for skipping is literally no one is going to use them. No one is going to use them because for the wasmGC languages, there is no reason to have data segments at all because they are not using linear memories. And anything they’d put in a data segment or an element segment, could easily be put in an array and they could just use array.copy.

AR: That doesn’t make sense to me. Of course you still have a data segment, my compiler when I compile string literals, I put the strings in the data segments, because the data has to come from somewhere right. And that’s why we introduced array.newFromData or something like that. So that is definitely useful, so you will have data segments, even with GC for that reason. And from there, it’s not hard to imagine you may also want to update an array from some segment. Basically the data segment can be used for both GC types and memory.

AZ: Why would you prefer to put that static data in linear memory instead of in an array?

AR: You don’t put it in linear memory, but you initialize the array from the segment.

AZ: You can initialize it from another array in a global.

TL: And that scheme would bottom out with array.init_static where you take the values directly from the stack.

AR: If you have a large string, you have to construct a gigantic array that puts every operand on the stack. You have to bootstrap it from somewhere. You want these array literals to be constructed from somewhere, not by each byte. 

ZB (chat): we are using array.new_data in Kotlin.

TL: I’m convinced having array.init_data is useful if you want to reinitialize any arrays, you want to initialize them from the data segments for the same reason you might create them from the data segments, if you want to reuse the object for some reason. I’m still pretty sure no one will use array.init_elem because there are no size benefits there, because when you create an element segment, you have to say what each thing is anyway. It’s not a compact format like the data segment. But it would be oddly asymmetrical to have array.init_data without array.init_elem. Okay so the full set is array.copy, array,fill, array.init_data, and array.init_elem. 

AR: Sounds good.

CW: Question about array.init_data: I know this is an awful thing that has come up before but would there be people wanting to use it as a constant expression, for example a global init? And then dealing with the fact that the data section is in the wrong place. 

TL: I think we can punt on that like we are punting on the same problem with array.new_elem.

CW: And we have the same problem with stringref.

AR: I think the problem only exists with new_data, not init_data, because that wouldn’t be a constant expression, it’s mutating what you already have. 

TL: If no demand to be a constant expression, then it’s moot.

AR: Not a constant at all, it’s mutated.

CW: I got confused between init_data and new_data.

AR: Confusing but too late to change that.

TL: copy_data or copy_elem would make a lot more sense, but yeah too late. As we said last meeting, I volunteered to do the tests for those instructions, AR you volunteered to do the spec work, and CW you volunteered to do the interpreter work. No rush, let’s wait for validation from v8 and our users that this is going to be useful to have. And then we’ll do all the other work soon.

TL: Anything else? Otherwise we can end early.

BT: I filed an issue on the spec repo for test locals which I had mentioned last time so if AR can take a look at that issue. 

AR: Yeah there is a bit of discussion from TL and me.

TL: Thanks for filing, look forward to discussing that further. Let’s go ahead and close this meeting. Thanks for the progress, see you in two weeks. And thanks to AN for helping with notes!
