![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the July 11 video call of WebAssembly's Garbage Collection Subgroup

- **Where**: zoom.us
- **When**: July 11, 4pm-5pm UTC (July 11, 9am-10am Pacific Time)
- **Location**: *link on calendar invite*

### Registration

None required if you've attended before. Fill out the form here to sign up if
it's your first time: https://forms.gle/JehrAB4gWbtHjybt9. The meeting is open
to CG members only.

## Logistics

The meeting will be on a zoom.us video conference.
Installation is required, see the calendar invite.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking (acting chair to volunteer)
1. Adoption of the agenda
1. Proposals and discussions
    1. Status checks
        1. Spec tests ([#396](https://github.com/WebAssembly/gc/issues/396)) and ([function-references/#100](https://github.com/WebAssembly/function-references/issues/100))
        1. Final types in Binaryen
    1. Discussion: Text format for final types ([#333](https://github.com/WebAssembly/gc/issues/333))
    1. Discussion: final opcodes ([#372](https://github.com/WebAssembly/gc/pull/372))
    1. Discussion: extending type difference to heap types ([#381](https://github.com/WebAssembly/gc/issues/381))
1. Closure

## Meeting Notes

### Introduction of attendees

- Thomas Lively
- Conrad Watt
- Bruce He
- Adam Klein
- Alon Zakai
- Ilya Rezvov
- Ashley Nelson
- Nick Fitzgerald
- Ryan Hunt
- Manos Koukoutos
- Ben Titzer
- Andreas Rossberg
- Francis McCabe
- Jakob Kummerow
- Matthias Liedtke

### Status

TL: In Binaryen I implemented final types. The way they are parsed is not quite spec compliant to avoid a breaking change for our users. Behind a flag is the spec compliant version. Communicated with our users and they are working on updating the text in binary they emit so we can just flip the default and be totally compliant. Jakob looked at the JS spec tests and type function references and found a bunch of issues. Andreas I saw that you have seen those issues and you’re planning to look into that

AR: Definitely, basically untested code 

TL: Great, thanks. Any other status?

AR: Spec work, updating the properties section so it has the soundness statement and some auxiliary rules for stating that. Other than that, I think everything is out there, except for missing pieces for bulk arrays. One item has no owner, extended name section. Am I the right person? I don’t know, haven’t looked at the spec. We should probably nail that down.

TL: The missing pieces I’m aware of for the bulk array operations is just validation, am I right?

AR: It’s validation and prose for execution.

TL: I’m working on validation and I’ll work on prose for execution as well. And I can also look into the name section part. 

AR: Thanks. I think then we’ll be covered, and I’ll just have to go over the remaining speculative hint issues.

TL: Spec notes, right. On the review front, CW I saw you did an initial review of the validation PR?

CW: I think with Andreas’ changes, that is pretty much done. I’ll look at that after this meeting. I’ll have the subtyping spec done by the end of this week.

TL: Sounds like we’re in a great place with the spec then. Also, AR put up the GH pages link so you can view the rendered spec linked from the readme on the GC repo. As we finish up landing new parts of the spec, the more eyes we get on it to catch typos and things, the better. 

RH: No real update on spidermonkey. Still . Working on generalizing?? , i31 patches are still in progress.

TL: Final types implemented as well?

RH: Yes

AK: Little update from W3C side. The W3C tag has closed the review for wasmGC, effectively approving it, no issues or worries with this. Thanks AR for chiming in on that 

RH: Would someone share the link to that?

AK: <linked in chat>: https://github.com/w3ctag/design-reviews/issues/814

NF: <comments from chat>
no big update on the wasmtime side. our contributor is still finishing up validation. I'm not working on gc stuff myself until I finish tail calls, which is close.

### Discussion: Text format for final types ([#333](https://github.com/WebAssembly/gc/issues/333))

TL: RH you are concerned about the text format here being slightly counterintuitive and confusing. Particular the MVP shorthand means final and then make it non-final you have to add sub. And it looks like that should be a no-op expansion of the syntax but actually ends up changing the meaning. Part of the Binaryen work, I’ve been spending time updating tests to add that sub, to make things non-final and it seems okay to me. Definitely counterintuitive at first thought, but having added it to a bunch of tests, I think AR’s suggested interpretation that sub annotation means you can interpret it as particppating in subtype relationships holds up in practice. What is your latest thinking on that? Did you still want to pursue alternatives?

RH: This is just the text format, so it doesn’t matter too much, since there are a lot of counterintuitive things. The reason is that we interpret things as final by default, but I think it’s fine. If people don’t like the syntax of inverting it, we can leave it as it is.

TL: Any other opinions?

AR: Its slightly more ergonomic, because you have to put in more sub. 2 keywords sub, sub final, the latter is written with a space. I mean it’s what you’re used to in other languages. You put final as an explicit marker. I think it’s more confusing the other way around, even with the shorthand.

TL: Close out this issue then and keep it the way it is

### Discussion: final opcodes ([#372](https://github.com/WebAssembly/gc/pull/372))

TL: Last time we didn’t have enough people to make a decision, but we checked the temperature. I posted a straw poll on the github issue. We have 6 votes in favor of not having holes, I voted for not carrying it forward, and AR voted for having holes.

AR: Don’t care too much, it's the binary format. But I think we are jumping back and forth, compared to what we used to do. I saw recently that someone mentioned pairs of expressions should somehow be aligned somehow, which means minor holes I think. GC Repo # 372

TL: Quick temp check, what do folks think of tiny holes to make groupings of instructions aligned?

RH: <in chat> No preference on any of this.

CW: We might have more instructions than could fit in holes, but we want to align groups of instructions.

TL: At that point, you’d have tiny holes and leave groupings of instructions for later.

BT: To have a null and non null variant, we want to have them 1 bit apart (as per Aske). Are there things beside that?

AR: Good Q. I guess something like br_on_cast and br_on_cast_fail. Probably also want to apply the same thing to the signed getters. I could see a bunch of instructions as a pair of variations of the same thing. Not sure what the exact rule should be.

TL: I think it’s more important they are next to each other rather than aligned. I can make a new hole-less opcode set as a next step.

AR: One thing I want to add is that I’m not sure I think we’re only discussing the instruction opcodes because those are the type op codes, because those already have various holes and we don’t want to move this around. 

TR: Are you referring to the part where some are negative coming down from the top?

AR: They always are but we are already extending certain groups that already exist. So func is an opcode that is already starting an opcode and we are adding some there.

TL: I’ll follow the existing pattern for the type.

AR: Why don’t you take the existing PR and change it.

TL: Yes, I’ll do that. I think we’ll have a consensus after we do that.

### Discussion: extending type difference to heap types ([#381](https://github.com/WebAssembly/gc/issues/381))

TL: Basically if you do a br_on_cast where you can statically prove that one branch is always going to be taken, then the other branch would end up, if extending type differences to heap types, then the other branches would end up with non-nullable references to type. which encodes that it is impossible to take. Or if the only way you could take that branch was on a null then it would have a nullable reference to none. So it would basically, as we iterated on these br_on_cast instructions, we’ve been trying to make the types as ??? as possible. Arguably an unnecessary step because Binaryen transformations could stop using br_on_cast and use different branching casts on these instructions, but I do think it would be good for a couple of reasons to make br_on_cast instructions as precise as possible as long as there is no computational complexity considerations. So if we had union types and it was O(n) to take the difference, that would be a problem, but we’re certainly not in that case in the MVP.

AR: I think it’s fine. It’s a bit more complicated, you have more case distinctions every time you do a branch. It’s a minor annoyance. It’s only used for completely useless casts, so I’m not sure there is a practical reason. It’s only  interesting if there are more interesting cases to make more precise.

TL: Cool, agree that it is only useful for useless casts. The thing is, from an eng perspective, useless casts pop up quite frequently in between Binaryen optimization passes. Being able to represent them more precisely and propagate them more directly in the IR types and pass to pass in Binaryen would be a big simplification. If you’re okay AR, I can make a PR for that change as well.

AR: Sure. On a meta level, I’m more skeptical of the language's changes just because Binaryen’s IR needs it. It’s a dangerous argument to make.

TL: Binaryen’s IR with few exceptions does try to be as close to wasm as possible, I suspect it’s not alone in that. Many tools for manipulating Wasm have some IR and are going to want it to be as close as possible. I use Binaryen as a motivating example here, but I do think the general principle makes Wasm more useful and would extend to more tools as well.

AR: One thing after the previous discussion that I realized is that it’s kind of a bit backwards. Opcodes exist for operational behavior, and we need to type them themselves. We are slowly turning casts into a monolithic thing which takes on more cases and subsumes I don’t know how many operators. This is an odd view of what the instruction is. We’re making casts into a general type annotation instead of having different operations for different things. What you’re using in the IR is much more general than it used to be. Maybe it’s ok now, but it could get a lot more complicated

TL: Understood, goes back to our discussion when we first combined the different cast operators and combined them into a single operator and that was based on feedback from Binaryen and also from engines because by seeing the entire cast in a single instruction, yes it’s more complex, but the code they generate is better and if they are separately generating code for operational parts of the casts. I still think it’s worth it. But I understand the concern as well. I have a lot of AIs but that is great. That is the end of our agenda. Anything else folks want to talk about?

CW: Are we going forward with the additional relaxation of type cast operators?

TL: With the proposed extension of type differences to heap types? 

CW: Yes.

TL: I think so. I’ll make a PR and I’m happy for folks to look at the details for what that actually means. If there are concerns, I’m happy to discuss them then. I’ll definitely pause and see if there are any concerns once we have the details up.

AR: One issue is multi-byte access. Clearly a post MVP feature, but I don’t know.

TL: I have been thinking we can address that problem space post-MVP, maybe very quickly post-MVP since it’s certainly a useful thing.

AR: In general it makes sense. I remember that I posted on the issue that we had the discussion on having reinterpret casts on references as a more general feature to have different views on arrays and also structs as long as there are fragments that map to transparent binary things. There is a certain overlap here, and I wonder if we should have both or only one.

TL: Personally I haven’t thought about it deep enough so I don’t have a formed opinion but that’s a good question.

BT: I don’t think we should have reinterpret casts on arrays because it will expose the machine endian-ness.

AR: That would be true with any of these operators, right?

BT: The proposal that was discussed was that the load and store instructions can be somehow overloaded. You can have load and store instructions on arrays, and these are little endian semantics.

CW: The Q of whether we think of them as the same instruction or mirror instructions of every load and store is mostly a binary format question, right?

BT: If you can do reinterpret casts, then you can do it on an array of i32, and you can see the byte order. That would force us to have a defined order on multi-byte arrays or multivalues, or force us to do something more expensive.

AR: Don’t we already commit to little endian in memory?

BT: Yes but we don’t have to commit to a byte order for in-heap arrays.

AR: Okay, interesting point. Food for thought. Not convinced that is worth considering but yes.

TL: A lot to think about here. Once we have time to think about it, I’ll be interested in engine implementer opinions.

CW: I don’t think this idea is fleshed out but my impression of that conversation in that issue was someone brought up a not fleshed out version of that idea of that array buffer could become i8 arrays

RH: Right now array buffers in SpiderMonkey have a very different representation than i8 arrays so anything is possible but that might be difficult from thinking about it quickly.

JK: There is lots of demand for that. I see it’s a desirable use case to do something there. I don’t know what we should do, but I’m leaning toward access to javascript style arrays. Maybe it should live under JS API just like imported strings. I’ve heard demand for this, and it’s worth tackling, but it’s also a big design space to think about.

AR: JS array buffers are not super simple and it might cause issues if we try to overload these notions with one specific type of arrays. I don’t know if we can make that coherent. I would agree with Jakob that it is probably something that belongs on the idea level.

CW: Orthogonal thought, even at the API level, the JS side gives me an array buffer, I can give the wasm side an i8 array. It could be a spec that only lives at the JS spec side.

AR: You can’t just easily convert it, so you’re basically having the same issue.

BT: Fundamentally, do we try to make foreign things show up as wasm arrays or make foreign things show up as a memory segment. If we try to make foreign things show up as a wasm array type, it has an implication for how you represent wasm arrays. I would like to optimize wasm arrays for the most efficient wasm implementation, so there are no indirections to some memory elsewhere. If we are thinking about bringing foreign things into wasm high performance, my preference is to make them appear as memory because they are inherently more powerful with the load & store instructions.

CW: Andreas was floating having a view of memory as an i8 array.

BT: Could be a strategy but it means i8 arrays have to be an indirection.

AR: Actually I wasn’t suggesting that, I was going in the direction of this should be something like in the space of strings, you have these instructions you can import somehow. It’s a bit more annoying with the zoo of load and store instructions, but I can imagine the particular program needs some of them, not the entire module so in terms of imports, not so bad. But I agree with BT that trying to unify them has a lot of implications. Arrays are a more general concept and having this special case for array i8 is probably more annoying. 

RH: I can see if you go in this direction, it will slow down i8. You’ll have indirection, and casting will get more complicated. It is great if array buffers are the common case, and everything else will be penalized. I think we should find another way to do it.

JK: Agree that array buffers are so complex under the hood and heavyweight and different from the wasmGC arrays we’ve had so far that from an implementation perspective, it would be unfortunate to unify. Interesting wrinkle from Dart is that they have abstractions on the Dart language level of the buffer style things that can refer to many things under the hood, which would require indirections or virtualization. When I pointed this out to them, they would happily take the overhead because they need it to model their language design. Maybe there is room for a relatively heavyweight tool available there that would like that tradeoff. 

TL: If there needs to be an indirection/virtualization. There is a case for putting it in userspace where Binaryen can get to it and devirtualize things. If it’s in the engine, we can’t devirtualize it, except locally since engines aren’t doing full program optimizations.

BT: FWIW, Virgil has a notion of off heap arrays. Virgil doesn’t target wasmGC yet but there everything is an index into the memory. i31 if you are memory segment. Otherwise a wasmGC array on the heap. 

TL: Clearly this design space deserves further thought, so let’s keep it going on the github issue. Targeting post MVP feature. We’re so close to finishing the MVP spec, we don’t want to throw this kind of uncertainty to it.

AK: PM point of view, as we get close to Phase 4, do we have a post-MVP label we can apply?

AR: We have it, I added to that very issue.

RH: Quick agenda item. On the final opcode renumbering, has there been any plans in v8 to implement on a certain day. What are the logistics? Want to sync up here.

JK: We currently have the origin trial running in chrome until the end of october. 118 is the last one. It should be on chromestatus.com. Want to land the changes in the second half of September, Chrome 119 feature freeze is September 19, branch point October 3, Ships to stable November 7th. ??? [couldn’t keep up with the rest]

RH: Just so I understand, what is the day it would hit stable. Was that October?

JK: I believe we hit stable in new encoding in early November.

RH: And that would be stable as in fully released in this scenario?

JK: Assuming we finalize phase 4 vote before that. I don’t think we have any action items on chrome other than waiting for phase 4 and finalizing binary encoding.

TL: Chrome 119 goes to full stable release on November 7th.

RH: Makes sense. I’ll have to look at our release schedule. I’m sure it’ll be fairly close.

TL: Thanks for a very productive meeting. See you in two weeks if there’s anything to discuss.
