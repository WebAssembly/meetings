![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the June 13 video call of WebAssembly's Garbage Collection Subgroup

- **Where**: zoom.us
- **When**: June 13, 4pm-5pm UTC (June 13, 9am-10am Pacific Time)
- **Location**: *link on calendar invite*

### Registration

None required if you've attended before. Fill out the form here to sign up if
it's your first time: https://forms.gle/JehrAB4gWbtHjybt9. The meeting is open
to CG members only.

## Logistics

The meeting will be on a zoom.us video conference.
Installation is required, see the calendar invite.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking (acting chair to volunteer)
1. Adoption of the agenda
1. Proposals and discussions
    1. Status checks
        1. Spec documents
    1. Discussion: relaxing br_on_cast annotation subtype constraint ([#381](https://github.com/WebAssembly/gc/issues/381))
1. Closure

## Meeting Notes

### Introduction of attendees

- Thomas Lively
- Slava Kuzmich
- Nick Fitzgerald
- Bruce He
- Ashley Nelson
- Ben Titzer
- Conrad Watt
- Jakob Kummerow
- Zalim Bashorov
- Alon Zakai
- Ilya Rezvov
- Andreas Rossberg
- Emanuel Ziegler


### Status checks

AR: In terms of creating PRs, the big ones are done but they are still under review, so blocked.

CW: I can get on them today and tomorrow, can start.

AR: That would be great, those are the most tricky. Validation, execution, binary format, text format are basically done. Module prose for execution I still have to do. Bunch of smaller appendices I have to do. JS API is also done now. Simplified that a little bit.

### Discussion: relaxing br_on_cast annotation subtype constraint ([#381](https://github.com/WebAssembly/gc/issues/381))

TL: Possibly relaxing br_on_cast and br_on_cast fail annotation rules. Right now it’s required that the cast output annotation needs to be a subtype of the input type annotation. Makes sense since there is no point in doing a downcast, but this lack of flexibility inhibits optimizations in Binaryen. So we’ve had discussion about how relaxing might cause problems with future extensions to the type system. It’s possible an optimizing engine that wants to produce the best possible code for a cast would have to calculate a least upper bound for types in order to generate that optimal code if we relaxed that restriction. Personally I’m unhappy with losing type information and having to insert extra casts and having our optimizations inhibited by this restriction so I would like to remove this.

CW: Having looked at your recent example in the post, it seems like the reason Binaryen would need to inhibit optimizations is because it too early propagates the refined type to the cast. In a situation where it wouldn’t create a well typed program. If you prevent that propagation in the first place, would that be a way to maintain all the same optimizations?

TL: Two ways to look at it. Either Binaryen does something that is overly aggressive and then has to back it out to comply with the subtyping constraint or it takes the subtyping constraint into account throughout the optimization pipeline and does fewer optimizations. Either way we are losing optimization potential

CW: Shouldn’t need to do pure optimizations unless it generates a cast in ??? type

TL: Fewer optimizations, I mean that if we consider the output type throughout the optimization pipeline to be the LUB of the input and the cast types rather than with just the input type. That means that the output type is as refined as possible according to the current typing rules but is not as precise as it could be under relaxed typing rules.

CW: I don’t think that’s the only solution. If I’m understanding, when you have a refined input type, you propagate the input type through the failure case of the cast. But because that doesn’t type check, you need to implement a downcast.

TL: Two options, assuming we don’t change the spec to relax this, we would just not do this to begin with or fix it up afterwards. But if we relaxed the spec, we wouldn’t need to.

CW: In that scenario, aren’t you optimizing a path that wouldn’t be taken because the input type cannot match the output type?

BT: Casts can let nulls through, so I think there are casts that would be illegal for all things not-null but would let null through. What if you just let yourselves put casts that would be illegal under the current rules and then change the casts. Is that possible?

TL: Yes, in our IR we would have a single br_on_cast, more optimal than allowed by the spec, and to fix it up we’d have to insert another cast or a scratch local, possibly a null check. A couple different ways we can fix it. The problem is where we would fix it, is in the binary emitter. We don’t want to have two different validation rules in our IR. Either the IR allows the more aggressive typing or it doesn’t. If it does, then we have to do the fix ups later and maintain the aggressive typing.

CW: The input type is no longer a supertype of the output type, doesn’t that imply that one of the branches wouldn’t be taken?

TL: Sometimes, also the case with nulls that BT said, where the output type would become nullable bottom reference, so a null can get through but no other value. And even in cases where one of the branches is impossible, we have optimizations that would go in and optimize that case, Binaryen runs one pass at a time. And we want to be able to emit a valid module, no matter what passes we’ve run. Even if we haven’t done that optimization, we still want to emit a valid module. We don’t want to depend on the fact that the branches could be optimized out and force ourselves to optimize it out. 

CW: You want to be able to run Binaryen in a mode where it doesn’t need to run optimizations afterwards to get rid of the dead branches.

TL: In the default optimization pipeline it tries to get rid of dead branches but if we’re just running a test that happens to not include the pass to remove dead branches, things should still work.

CW: Things could still work but you lose a couple of opportunities at refinement in the failure branch.

TL: If we apply these expensive fixups or propagate less expressive types

BT: Can we keep weakening the supertype until it’s a supertype of everything.

TL: That would be the fix up, take the LUB of the input and output type, so you weaken the input type, but that also weakens the output type on the failure mode of the branch

CW: Is it the case that low propagation optimization, It’s only if you miss out on one. Propagating less precise type + optimizations that determine the type to be taken.

TL: We can optimize br_on_cast onto some other br or optimize the branch entirely to fix this problem, so if you br_on_non_null, you can transform it to get the more precise typing and optimizations. I think that in general, that would require adding a cast and a null check. So you turn a single cast into two casts.

CW: How does the first of the two casts type check in that scenario if the combined cast doesn’t?

TL: Only the combined cast has this arbitrary rule, we don’t have that on regular casts.

CW: Really?

TL: Regular casts like ref.cast have an input type that is not annotated and the only annotation is the output type. The dynamic type of the input to the cast can be unrelated to the output type to the cast because by subsumption you can treat it like anyref. AR said generating optimal code for casts would also require the engine to do a LUB, so maybe we’ve screwed that up already.

CW: I was thinking that as well.

AR: You may be right, I was never happy with the monolithic design.

CW: In my head, the monolithic design had input and output annotations.

TL: Ref.cast doesn’t have an input annotation because it’s not necessary for principle types. The only reason we have a type annotation on br_on_cast is we have two branch arms so to get principal typing.

CW: I don’t care about relaxing br_on_cast if we’ve already screwed up ref.cast

TL: In the future if we have union types, perhaps you can get more accurate information by getting the exact LUB. 

AR: Wait until you get generics, because then it’s coming back to you and you will have all these problems anyway and then you’ll have to do more work to do the cast path in the engine as well.

CW: If you reference a generic, you need to cast a generic with a type annotation, you can’t use the ref.cast.

AR: Sure, but that wouldn’t change anything. The annotation doesn’t give you additional information. 

CW: In one possible future we have slightly less efficient code gen for casts

TL: Imagine a cast where we have an input type that is the static type of the input, that determines what the output is on the failure arm. The output type annotation that says what you’re casting to, and a third casting annotation that says what the LUB is so the engine can do some nice codegen without calculating LUB.

AR: Assume the LUB is always the input. No value in separate annotation.

TL: There is, then you can refine the output type on the failure arm.

AR: For casts in general, you can make the argument that casts are supposed to check, if you have two types, I want to check this difference, generate code for me for checking this difference. It would be a bit more explicit. That would be a good idea for other casts. I expect you to generate code for these two different types.

BT: Did we decide that just because of space?

TL: Are you asking “did we decide not to have that input annotation just because of space?” Not just to save space, we never talked about putting an input annotation on this cast before because in the MVP, it’s not useful, that’s why it never came up before. In the MVP, all you do to generate optimal cast code is to figure out what the abstract LUB type is. If you have two struct types, casting from their specific LUB is no better than casting from generic struct type.

BT: In a baseline compiler that doesn’t construct types, you only have the immediates, you wouldn’t know the input type is a struct. 

TL: For the baseline compiler, that’s true, so the pessimistic code would have to cast from Any.

BT: I recently had a look at all the baseline compilers, I think SpiderMonkey & V8 reconstruct types as they go, so they have the LUB effectively, but not all baseline compilers, Wizard doesn’t do that. 

TL: For baseline compilers, I’m not as worried, it’s a tradeoff at the baseline. It can choose to reconstruct types or not. Ben, are you advocating that we add an input type to ref.cast as well?

BT: I see its value but no, not really. Given where we are in terms of churn, I don’t see a big enough benefit to do that. 

TL: I would be happy, in the future, when the type system becomes more complex and generating optimal code becomes more complex, I would be happy to add a version to ref.cast instruction that does take a useful input type. Or a version of br_on_cast instructions that takes an additional LUB, to reduce the work the engines have to do. For the MVP, I don’t think it’s necessary. And the benefit of propagating the more precise type information is much bigger than the disadvantage of some work to calculate the optimal codegen, especially if we’re already doing the work in ref.cast.

CW: With this revelation, I agree it would be consistent with ref.cast to go with TL’s suggestion of relaxing br_on_cast.

AR: Still uneasy about the implications it might have.

CW: It seems like the main implications are how efficient the codegen is, so at worse, something naive.

AR: The other was about the type difference and if you want to have something more powerful there. In increasingly expressive type system, the type difference becomes similarly hard to compute as the LUB. That’s my other worry. I don’t have any concrete examples, need to think more deeply. This might easily bite us, is my hunch. Unless we compromise on that, we want to have the most precise output there. There is a catch.

CW: A version of the br_on_cast with the LUB annotation, would it be possible to segregate the types so the more complex types are not allowed to be passed as input into the one without, and you have to use the more annotated version. 

AR: I’m not sure that would be easy but we could do the unannotated version would compute the less 

CW: Currently we have a precise output type but maybe it would be a less precise input type and that doesn’t seem so bad.

TL: Either that or the less annotated version is, the missing LUB annotation is Any. 

AR: That would be ideal, sugar shorthand. Not sure if possible, we’d have to see.

BT: Where we are now, with the types, the branching casts that have the two annotations, everything the engine has to know is in these two annotations. So the validator is between the two type annotations. So it becomes nulltype or unreachable. 

AR: Can you clarify?

BT: Generate code for br_on_cast with two annotations, with the types we have now, you don’t know anything from the abstract stack. So the check the validator does is the same for rejecting the allocated casts, so it’s effectively the same for the code generator to do the same check, and generate a null check or unreachable. 

AR: There is nothing to force the producer to generate the most precise input types. You can try to cast from A to B, and annotate with Any if you don’t want to have the output type be precise. I don’t know if engines are too optimized for A instead of Any, but they could. So this is another place where there is too much machinery for this one instruction, IMO. I was expecting that with two input types it would not do better with optimizing based on the inferred type, but I would assume producers would already insert the best type they can so the engine just uses that and is done. With the observation that cast doesn’t have that information, they can probably do it anyway, so just as well for b_oncast.

JK: Of course optimizing compilers try to optimize. For example for vtables with br_dispatch, the type system forces you to make it generic, then you inline and inlining allows you to drop a bunch of checks. 

CW: Do you see value in having ref.cast with input and output annotations?  

JK: Nope, not for the MVP. Wouldn’t get any value, just burn a few cycles on validating the input type. I’m quite happy with the state the ref.cast is in now. If and when we have a more complicated type system, we can introduce a variant.

CW: Thank you. 

BT: I agree with that, if we get to a place with generics, we can introduce a cast with type parameters that is capable of dealing with type parameters and has more annotations. 

TL: Sounds fantastic to me as well, anything else to discuss?

CW: AR, do you want to think more of hairy scenarios?

AR: Uneasy, probably won’t come up with something in the next couple of days, because of limited time. We can tentatively decide on it now, and if new info comes to light, we can reconsider

TL: I’m happy to reconsider this if new things come to light.

CW: It’s a problem that could be fixed in Binaryen but you’d have to change how types are propagated through branching casts. 

AR: But basically, you want to detect casts that are dead because they can only succeed or fail. It’s a bit weird this can come up. One problem is you don’t want to have two typing rules for the instruction. The other thing is you have the liberally typed way or the rigidly typed one, and when you spit out the wasm code, you transfer one to the other. I’m not sure I’m totally convinced we’re fixing it on the right end, but I don’t have a strong argument at this point. I would prefer having the two annotation casts, but I’m not actually suggesting that right now.

TL: That sounds like a totally reasonable thing to have in the future once it’s more useful. I agree in principle but not on timing. In Binaryen, this is all fixable by transforming the code and it’s a question of for engineering reasons, reducing the number of transformations we have to do in the Binary emitter. It is fixable but it is not one that we would be happy with.

AR: My take is you want some of the transformations, but something looser than the target language. So you would have to have an IR that is a bit relaxed and then translate it back to the real thing, which is not uncommon in compilers. It is how many of them operate.

TL: That’s all right. Hopefully, you can see why from our point of view, the fact that we want to emit something, it seems like a bug in the target language. Please speak up if something with the type annotations does come up.
