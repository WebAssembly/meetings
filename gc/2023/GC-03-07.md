![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the March 7 video call of WebAssembly's Garbage Collection Subgroup

- **Where**: zoom.us
- **When**: March 7, 5pm-6pm UTC (March 7, 9am-11am Pacific Time)
- **Location**: *link on calendar invite*

### Registration

None required if you've attended before. Fill out the form here to sign up if
it's your first time: https://forms.gle/JehrAB4gWbtHjybt9. The meeting is open
to CG members only.

## Logistics

The meeting will be on a zoom.us video conference.
Installation is required, see the calendar invite.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking (acting chair to volunteer)
1. Adoption of the agenda
1. Proposals and discussions
    1. Status checks
        1. Resolving cast annotation issues
        1. Finishing JS API (https://github.com/WebAssembly/gc/pull/355)
        1. Bulk array operations (https://github.com/WebAssembly/gc/issues/313)
    1. Discussion: Implementation-defined limits ([#335](https://github.com/WebAssembly/gc/issues/335))
1. Closure

## Meeting Notes

### Introduction of attendees

- Thomas Lively
- Ilya Rezvov
- Ashley Nelson
- Ryan Hunt
- Alon Zakai
- Aske Simon Christensen
- Rick Battagline
- Manos Koukoutos
- Asumu Takikawa
- Jakob Kummerow
- Zalim Bashorov

### Status checks

TL: Check in on a few things in progress. I’ve been working on Bulk Array operations and I have a Binaryen implementation done. Now I’m working on spec tests. I’ve listed out 100 different tests I think I should write for it, so I’m working on cranking those out. I saw that Aske had suggested we should add additional instructions. Since I already have so many tests to write, I think I will not write tests for those instructions right now, but I would be open to prototyping them and seeing if they are useful and if based on that data we think they are useful we can add specification and tests and all that for those instructions. Does anyone have related updates? Or thoughts on Aske’s instructions?

RH: What is the set of instructions? I know about Array.copy.

TL: I pasted in the [link](https://github.com/WebAssembly/gc/issues/313#issuecomment-1458062757) in chat, people had previously discussed wanting a complete set of operations rather than adding just array.copy to the MVP, so the complete set is array.copy, array.fill, array.init_data, array.init_elem. These are 1:1 with the bulk memory instructions. The additional instructions Aske pointed out would be array.new_copy which is similar but allocates a new array and fills it with the copied data. And array.init_fixed which is like array.new_fixed in that it takes values from the stack but it could write those into a pre-existing array. Right now we are adding 4 operations and there are 2 additional operations Aske pointed out.

AC: I was looking at the duality between the new instructions and the array init instructions and saw these two holes in the duality. I think array.new_copy can be very useful, not so sure about the other one. But in the case where you want to create a new array containing the data of some sub-section of an existing array, the only way to do that with the currently proposed bulk operations is to create the array, initialized with some value, and then copy from the existing array to the new array. So with array.new_copy you can do that in one step instead of having to also initialize the array. I think that could be useful.

RH: I think that could be useful too.

TL: I will be sure to implement it in Binaryen and then coordinate with v8. Or Ryan, do you want to get it in Firefox?

RH: Eventually we’ll implement it.

TL: I don’t want this holding up the MVP, so if we get to the point where all the other issues are resolved and folks are interested in shipping, we should just drop it and go to post-MVP. But this seems like something useful to do during the slack space while everything else is cleaned up in parallel. That’s it on bulk operations, I hope to have PR up later this week with spec tests. Andreas and Conrad aren’t here but they signed up to do the spec and interpreter work.

TL: Asumu, can you do a status on the JS spec?

AT: The status is there is a draft spec and it’s in review. It is mostly complete, but there are some changes needed because the JS spec depends on the core spec which hasn’t been written yet. And there are changes coming that will affect the JS spec. About as done as it can be done right now. Not sure if there are any merge blockers, unless anyone has any issues with that. That’s the state of the spec. I also had a PR for adding tests to the JS API and I think those are in a pretty good state too. I don’t know who the best person to review and approve that is. More tests would also be useful. One thing that’s come up, I talked to Thomas via email, but due to project staffing changes, I’m not going to be able to devote a lot of time to WasmGC topics in the future. I can do small maintenance tasks, but unlikely to have time for big changes, tests are included in that. So if anyone has bandwidth to work on those tests, that would be helpful.

TL: Definitely agree for the spec PR, let’s get that merged and ping Andreas about that. Better to have it merged than outstanding and open. Makes sense that when the core spec is written, we may need to change some things.

JK: We have a fairly large set of tests in v8. They use V8’s testing infrastructure, but the test contents would be engine independent.

TL: That would be great, sounds good. Also wanted to check in on resolving cast annotation issues but Andreas isn’t here so we can push that. Just wanted to check-in because we have a new property that determines which things should have annotations but I don’t think we have a PR that adds annotations to the merge and cast instructions. Needs to get done, but we can handle it offline. 

TL: The other thing I wanted to talk about today was implementation defined limits. Here is the issue link: https://github.com/WebAssembly/gc/issues/335 

RH: Before we get to that, on the status checks, has the text format been written yet? I’m guessing it’s a *WIP* since it’s part of the spec, but impacts writing tests since we write them in the text format. It would be nice to have the text format standardize these instructions. 

TL: Great point, I don’t think we’ve formally written any text format stuff. A few fragments have been implicitly specified, because they are used in tests that have been checked in along with the spec interpreter. Defining types has a fairly known format that is fairly stable. The text format for individual instructions can also be read directly out of the MVP doc where they are described, So I don’t think there is too much left, beyond the instructions and type definitions. Fairly stable but not written all in one place.

RH: I expect the instructions are pretty simple, but the one that had the most decisions in our text parser was defining types, especially recursion groups, the syntactic sugar for a recursion group. But if there are tests for that already, I can see if I made the same decisions as the spec interpreter did.

TL: The fully expanded form is fully stable, but the sugar we are going to add to the spec tests is up for discussion. I filed this issue, https://github.com/WebAssembly/gc/issues/333, a while ago proposing a bunch of abbreviations. We haven’t made any decisions based on that. But this is what I’ve implemented in Binaryen’s parser. I would just stick with the fully expanded versions right now and not do any abbreviations until we’ve had a chance to discuss them further.

RH: In terms of testing it’s subtype, structural type, and (missed this)

JK: We could also add a de facto reflection of what’s been implemented. In the long term we need a proper spec, but in the short term, this might be the quickest way.

TL: I think a short PR that adds in what we have agreed upon today, makes sense. I can do that today.

AC: Is the extra syntax for final types and the defaults for that also in there?

TL: I’m not sure actually, good question. I think Andreas added tests that use final types, so there should be some text format there. I haven’t looked at it myself. Any other status before we move on to implementation defined limits?

### Discussion: Implementation-defined limits ([#335](https://github.com/WebAssembly/gc/issues/335))

TL: Implementation defined limits, issue 335. Most of these are non-controversial, million recursion groups and a million total types, no one has disagreed with. No one has disagreed with not having a limit on Array sizes. Most of the discussion has been around subtyping depth limit. OCaml folks and Dart folks say 31 seems low for their use cases. We have Jakob here, I know 31 was chosen to make a bit-packing scheme possible. If we need to make it significantly larger, does the limit really matter? Is there a difference between 100 and 10,000

RH: The bit packing scheme is no longer relevant because the depth doesn’t show up in the value type anymore. That may become the case in the future with explicit RTTs, but I don't know the plan of record for that. Our bit packing scheme I was just looking at, it would be hard to support more than 64 using our existing scheme without doing an overhaul on it. So that’s the rough limit on that. Once you get past that, it doesn’t matter if it’s 100 or 10,000 for the bit-packing part. The other part is the metadata part, space usage would get high for the constant time subtyping trick. We can have internal limits around that. And possibly we could have a heuristic around a depth of 64, we switch to linear subtyping tricks or something like that, but that might have other impacts. But that might be a big performance cliff. 

TL: Aske, for Dart closure representation use case, 31 seems low, what would you expect to be a reasonable upper bound the language implementation would be okay with?

AC: If this were completely unconstrained to the other limits in place, another limit we have in Wasm is at most 1,000 parameters to a function. So 1,000 would be enough here. The in-practice depth would be the number of different numbers of parameters to closures that would appear in the program and in practice this is probably not very big. Functions with many parameters tend to use named parameters so those are not counted with the limit at least in the documentation. So it’s probably unlikely that a limit of 64 would cause any problems. If some program happens to take a lot of positional arguments to function, then it breaks down. I think OCaml case here is more precarious as I understand it. In their case it’s the # of fields in a struct, which often grows to much bigger numbers. And even if they did the same optimization that I suggested where it’s not the number of fields but the different numbers of fields then 64 could become a low limit in a big program.

TL: Definitely will check with them to get more details. Provisionally, would a limit of 1000 be concerning for implementation? I know the space consideration you were talking about could be potentially serious, Ryan.

RH: On the bit packing thing, if it came down to it and we were adding explicit RTTs, we could find room for representing 1,000. It might involve an allocation, but I would hope that would be rare. I’m okay with setting that aside. On the space concerns, it could grow quite a bit if we just naively did that. Even in the OCaml case, they might trigger that without trying to write pathological tests. So there could be some pressure to allow it to succeed but fall back to a slower casting technique which might not be so great. I don’t have a great suggestion here unfortunately. So I guess the question is what do languages expect to happen when they have a very long subtyping chain. Do they still expect constant or can there be a linear fallback? If they are okay? I'm okay.

TL: Wonder if we can come up with something fancy and have a logarithmic fallback

JK: Linear time subtyping checks will be expensive if your subtyping chain is long. It’s exactly the long cases where the constant time is interesting. ON the v8 size, we have the same concerns Ryan has expressed. If it’s small, some power of 2 - 1 so 63 instead of 64. My thoughts on OCaml is if we did 1,000 would that be enough or do they need 10,000 or 100,000? At some point, it becomes unwieldy for dealing with small limit optimizations. My take is I don’t mind adding 1 more bit, how would folks think about the conservative choice of having 63 as the limit right now and if a concrete use case comes up we can consider raising the limit. 

TL: I’d want to check in with the OCaml people before committing to 63. But if their use case is 100,000 just as much as they need 64, then yeah 63 probably sounds good.

RH: SGTM, I don't know enough about OCaml use-case, but it sounds like they are dealing with a situation where they need a dedicated feature. Shouldn't block MVP, from a spec standpoint down the road we can agree to raise the limit. 63 sounds like a good start.

TL: Cool. Any other thoughts on this topic or other implementation limits Struct fields is currently 2,000 and we haven’t heard any feedback that it was too limiting right now.

JK: Yes that’s my understanding, I don’t feel strongly if it’s 2,000 or 10,000. If we think 10,000 is a rounder number, I have no complaints. 2,000 does seem to be enough.

RH: We have no complaints here as well. 

TL: Of course we can always raise it if someone does run into it, but if the implementations don’t have any special considerations to keep it lower, then I would say let’s do 10,000 and reduce the chance someone is going to run into it.

JK: One consideration, we recently started doing a special null sentinel so we can do trap based null checks. So in the straightforward way, it requires having a null sentinel that is as big as the biggest struct can ever be. There is a cost, it’s not huge, but it means that every single Wasm module will burn because the size needs to be encoded in the engine. We can do a fast hybrid [where larger structs have explicit null checks], but that would make implementations more complicated when we do the switchover. That is the cost of raising the limit to 1 million fields.

TL: So say we did 10,000 fields it would be the size of a v128 * 10,000 so 156KB? 

JK: Exactly.

TL: Maybe we keep it at 2,000 for now then. Sounds like there are no strong opinions. 

AC: I think 10,000 sounds like a good pt, Jakob’s concern is 10,000 would be 40KB or so. 

TL: No, it’s 156KB since v128 is the largest possible field/

AC: So yes 160KB then, yes.

RH: Does this memory need to be committed or reserved?

JK: Just reserved.

TL: Okay, 10,000. Great. Are there other limits we need to talk about? Number of operands to Array.newFixed, thinking we should have a limit to the number of operands on the stack in general. What is the latest thinking here? 999 was too low and now it’s 10,000 which is sufficient in v8. Should we just call this 10,000 for now?

RH: I think this is okay but there might be difficulty with our baseline compiler that might overflow our maximum frame size. I have to double check what our maximum frame size is right now. I don’t have an issue with it as long as we're allowed to possibly fail lower than that. We’ll do our best not to do that.

TL: Some can always fail like allocations, but I think the goal of the implementation defined limits is to provide firmer guarantees for web portability. So I would be interested in hearing the maximum frame size you’re working with so what is the max in your implementation. I guess it depends what else is going on in that farmer, and it not about this one instructions

JK: It’s hard to say, and not the same frame, it’s the same stack. If you have some reasonably deep recursion and then array.new_fixed you can run out of stack space. And then the types matter whether it’s i8 or i128. I think we always use 64 bits on a 64 bit machine because we fill all the registers.

TL: I would be fine setting the limit as the highest possible number that has a chance of working or 10,000. If we deterministically fail below the defined limit, we should lower the limit. 

RH: We have ½ MB for a frame. There is a comment that says the reason is 1000 parameters, 50,000 locals and 50,000 evaluations for the compiler. So there is still some space left for that. If you are doing a Array.new_fixed then I believe 10,000 is fine. I can verify after the meeting.

AC: The use case I’ve seen is global initializers and they are not that big. Are the concerns different in global initializers than they are in functions?

RH: Good point, because global initializers will use our interpreter which should fare better. It will be slower but have a higher limit.

AC: So how would it work if we had a limit of 10,000 for the stack inside the function body but a higher limit for array.new_fixed on itself which can be used in constant/global initializers 

RH: One concern I have is the speed of doing this because that’s a lot of values to push and pop off the stack. Are these strings that we are initializing here?

AC: Strings or big arrays. I’ve also seen arrays bigger than 10,000 sometimes

TL: Would we expect that at some point, the benefit of getting a baseline compiler to fill out these arrays with an initialization function would be faster than filling out an interpreter with the array in a global initializer? So there is some crossover point Aske where you might prefer to do it in an initialization function for performance reasons.

AC: You still have one instruction per value and this code is only run once, so we assume the baseline compiler would take longer to compile than the interpreter running them.

JK: Probably a fair assumption, yes.

RH: Is it possible to use array.new_elem or array.new_data?

AC: Yes but we’ve decided not to have that in the MVP.

TL: This goes back to the section ordering problem, I forget if it’s data or ordering or both.

AC: Data is the simple one, the only thing that needs is the number of data segments which we have this extra section for. It’s just not placed early enough. So one of the suggestions in the discussion is could we allow that section to appear earlier. 

TL: This is the data count section that was introduced.

AC: Yes for array.new_elem, it was more complex because it could introduce cyclic dependencies between the global initializers and the elements because the elements could also contain constants. So there was discussion for how we can allow this in a way that guarantees to not run into cycles or can detect cycles and give an error. I don’t think we had agreement on the right approach.

TL: In a perfect world, we would solve this, but if we solve this for the MVP it would delay the MVP which nobody wants.

AC: Ideally there would be a limit.

RH: That helps jog my memory. I’m concerned about the performance of array.new_fixed initializer expressions. I feel this should be discouraged but I understand it’s nice to have. It would be nice to have something optimized than pushing and popping for the interpreter.

TL: I suggest we stick with 10,000 for now and post-MVP we return to this question of what to do with section order. Which is really what you’d want for the global initializers in the first place. I think that’s all the implementation limits for now. Any other spec limits we should discuss or comments about what we’ve discussed? I’ll try to get the implementation limits decided and closed. Thanks all, see you in two weeks. 
