![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the February 13th video call of WebAssembly's Stack Subgroup

- **Where**: zoom.us
- **When**:  February 13th, 17:00-18:00 UTC ( February 13th, 9am-10am Pacific Standard Time)
- **Location**: [Zoom call](https://zoom.us/j/91846860726?pwd=NVVNVmpvRVVFQkZTVzZ1dTFEcXgrdz09)


## Participants

Daniel Hillerström
Sam Lindley
Francis McCabe
Ilya Rezvov
Thibaud Michaud
Andreas Rossberg
Luke Wagner
Ashley Nelson
Deepti Gandluri
Benjamin Titzer
Brendan Dahl
Adam Klein
Thomas Lively
Ross Tate
Ryan Hunt
Zalim Bashorov

## Agenda items

1. How to add stacks to V8 (Ilya Rezvov)

IR presenting [slides]() TODO: link to slides

## Meeting Notes

AR: Is V8 investigating conservative GC for all frames or just C++ frames?

IR: (missed answer)

SL: Growable stacks, are these segmented stacks or are you expecting to move the stacks?

IR: That's the next slide!

BT: How would that work on Intel with the shadow stack?

IR: When we call, we push the return address on shadow stack and never replace return addresses, so we don’t have to adjust it. There could be one case with top frame on stack grow, but we don’t have to do anything involved because if we copy frames, we keep return addresses the same so we don’t have to change in the shadow stack. Segment stacks as well.

TM: Don't think there's anything to do for stack growing, just stack switching.

AR: When you copy over, you keep the addresses so that would require VM techniques and would need to be required if you want to handle native stack frames as well or they would be completely gobbled when you copy to different addresses. Presumably that means you can’t use copy on grow on i32 platforms or something like that

FM: To be clear, we’re not going to have native frames on these stacks. 

IR: Because of switching to shadow stack,makes our life a bit easier. We chose segmented stacks so we don’t have to worry about this. When we create a new stack, async.wait but never suspend, segmented stacks allows easier optimization because we can continue to execute, use the same stack for freshly created greenthread. And if we return to parent, in this case we can have immediate stack overflow and build a new stack segment for parent. An optimization we call stack stealing, because you steal stack from parent to use for execution. A bit easier to do with segmented stacks.
SL:
BT: Sampling profiling, is that simple to support? Are there plans to support?

IR: Falls in debugging and profiling bucket. I haven’t thought about it yet, I’m not sure.

FM: Currently if you use the pthread??? API for something, it won't crash, but it won't sample your WebAssembly code. You'll need a new WebAssembly-aware profiler.

SL: You mentioned these two approaches, copy on grow and segmented stacks. Another approach that hasn’t been mentioned because maybe it’s been discounted is the variation of growable stacks where you use VM to avoid having to change the address of the stacks at all. So the libm library that Ben Lyon created for instance. Have you considered this approach and decided it’s not worth doing?

FM: We have and it doesn’t scale.

SL: What would the various entries be in the table for that case? Is it ruled out from the start because you don’t think it will scale to smaller platforms?

SL: Do you have a feeling for the relative costs between "heavy" and "light" stack switching?

IR: Right now, still limited by mutex acquisition, so we cannot properly measure and get numbers. My feeling is it shouldn’t be too expensive, several additional instructions for updating execution state. Could tax us a bit because it’s not cache friendly. We hope it won’t be prohibitive.

SL: The priority is to optimize the mutex?

IR: Yes, optimize mutex and it shouldn’t be expensive for existing calls. If we have to introduce green threads and we have to use it, then it’ll be a little bit less efficient but it will be usable.

FM: How much work has this been?

IR: It's a huge project. We already spent half a year developing it and will continue this year. More than a year for rounding up to two people.

SL: How much more work would it be to do the things you listed? That you said should be done?

IR: Hard to say because right now we're working on getting just one platform done. Next platforms should be slightly cheaper.

SL: You don’t have all of the segmented stack infrastructure done or the allocators, those kinds of things. Would that be something that is relatively easy to plug in?

IR: Yes, a new allocator would be easy to plug in because it's not integrated in V8.

RT: What’s the biggest cost of switching?

IR: You mean switching between stacks?

RT: What takes the most time to switch between stacks?

IR: It's the mutex we want to eliminate.

TM: I don’t think we’ve done presized yet.

IR: For each switch we have to update several roots in V8. It's not too expensive, maybe several dozens of assembly instructions, mostly accessing and modifying memory. Without mutex it shouldn't be too expensive.

RT: It should look like a function call with a little extra stuff + the mutex call.

IR: We're targeting 5 to 10 function call overhead.

BT: Do you have a list of design alternatives you rejected and a record of why you rejected them?

IR: I mentioned movable stacks, I’ve rejected it because of CFI and potentially less room for optimizations in the future. Also, initially we tried not to switch to central stack, our grow routine wrappers of native code but it requires. We don't have a special requirement for native code so we have to annotate all runtime calls with how much space we need. And it sounds like a pretty hard to maintain and estimate tasks. So switching to central stack was a better solution here. 

FM: The main one would be the VM for stacks. The issue is we have the traditional problem with real threads, you have to guess how big the thread would be. If you’re going to run on small platforms, even 64-bit platforms like Android, you run out of address space pretty quickly. And there are some embedders that don’t have VM but that’s less of our concern.

SL: One downside of segmented memory is they allow you to have pointers into the stack, whereas if you're moving the stack around, you have to reload the pointers. Is it not relevant for v8?

IR: Not relevant, we still have to update some small pieces of state.

SL: Like what?

IR: Frame pointers. And we store sometimes references to arguments, arrays. So there are several places.

TM: If we had native frames, this would be less of a problem but we have JS.

SL: That must be another design decision you discarded immediately? Having native frames in the segmented stacks?

FM: Originally we were going to do that.

IR: THe first was conservative GC scanning, it crashed in our POC impl. So now we have some code that gathers all secondary stacks in special leased process. It’s more work to do. Conservative GC you have to be aware of what you’re doing and traverse the segmented stacks, so it is more coupling to subsystems.

FM: To answer Sam’s question more directly, there is documentation here. We have design documents that cover this.

SL: Where are they?

IR: We can revisit and publish more broadly.

RT: Another issue I remember was overflow potential.

FM: We looked at one possible strategy which was annotating the code. As Ilya says, we could do it for our own code, but apart from everything else, v8 is embedded in other systems and it would be an impossible burden for those embedders.

AR: In what way is it relevant? You don’t have stack overflow checks

RT: Virtual memory handles it if it overflows in a typical way, the VM says hey, stack overflow.

BT: It is significantly more difficult to make those checks work with VM than advertised. It doesn’t work to use the pthread library with virtual memory stack overflow checks.

RT: Can you clarify what you mean? Because C++ code doesn’t check the stack overflow.

BT: In C++, it is undefined to overflow the stack. In linux, you can’t use the pthread library. You have to use your own stack segment with Linux to do overflow checking with stacks.

FM: Why because the stack you get is not protected?

BT: Linux has this idea of automatically growing stack segments for you, handling traps. So if you try to create red zones it doesn’t work because you’ll be confused by the heuristics in the kernel for the stack. So if you want to use VM in your own stack, you have to roll your own, it’s the only way to make it completely stable.

RT: Are you saying virtual doesn’t require any VM to do stack overflow stacks.

BT: It does, but it uses its own stack segments, and doesn't use the pthread library.

RT: What does virtual do when it calls out to its own C++ code?

BT: It does not call 
















### Adoption of the agenda

### Adjourn



