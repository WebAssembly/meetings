![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the January 27 video call of WebAssembly's Community Group

- **Where**: Virtual meeting
- **When**: January 27, 17:00-18:00 UTC (9am-10am PST, 18:00-19:00 CET)
- **Location**: *link on W3C [calendar](https://www.w3.org/groups/cg/webassembly/calendar/) or Google Calendar invitation*

### Registration

No registration is required for VC meetings. The meeting is open to CG members only.

## Agenda items

1. Opening
1. Proposals and discussions
    1. Update on custom descriptors (Thomas Lively, 30 minutes)
        1. Possible phase 3 vote
    1. Advance `Rounding Variants` to Phase 3 (Paul Dennis, 30 minutes)
        1. present testcases in forked repo
        1. poll for phase 3
1. Closure

## Agenda items for future meetings

*None*

## Meeting Notes

### Attendees

 - Conrad Watt
 - Paul Dennis
 - Kloud Koder
 - Derek Schuff
 - Robin Freyler
 - Keith Winstein
 - Paolo Severini
 - Yui Iozzelli
 - Chris Fallin
 - Nick Fitzgerald
 - Thomas Lively
 - Andreas Rossberg
 - Ryan Hunt
 - Ben Visness
 - Ben Titzer
 - Sam Clegg
 - Michael Ficarra
 - Manos Koukoutos
 - Heejin Ahn
 - Ryan Diaz
 - Rezvan Mahdavi Hezaveh
 - Zalim Bashorov
 - Steven Fontanella
 - Chris Woods
 - Bailey Hayes
 - Kevin Moore
 - Emanuel Ziegler
 - Jakob Kummerow
 - Julien Pages
 - Brendan Dahl
 - Mattias Liedtke
 - Jeff Charles
 - Johnnie Birch
 - Richard Winterton
 - Guy Bedford
 - Ricky Vetter
 - Alex Crichton



### Proposals and discussions

#### Update on Custom Descriptors (Thomas Lively)

TL presenting [slides](presentations/2026-01-27-Custom Descriptors & JS Interop - January 2026.pdf)

CW: are the performance changes at least stable/predictable so applications can choose to use CD or not based on that?

TL: if you have a good benchmark suite you can run it and see what happens, it’s fairly stable in that sense, you can choose CD or not. How well those match your production workloads is on you.

AR: curious how ref.test can access the map for null?

TL: it doesn’t anymore… but it used to be that if you did struct.get on ref.null would trap because the fields were inaccessible, but the internal fields were accessible. Jakob could speak more but we’ll skip it for time.

TL continues with “Type System Complexity”

JK (chat): Andreas: in short, we're shifting work from ref.get_desc to certain cases of ref.cast. It's a tradeoff.

BT (chat): Are there numbers on memory consumption as well? Did they change since October?

NF (chat): slash does anyone have the numbers from october handy?

JK (chat): Ben: no, still saving one field per object, which is probably effectively around 10% for many workloads. Fixed memory consumption goes up a bit, mostly because there are more types, because Binaryen can do less type merging with CD.

(type system complexity slide)

AR: Not sure I buy that that’s similar. When you just have regular mutually recursive fields, validation doesn’t need to know anything about the other, but with descriptor/describes you have to check them together in an entangled way. We haven’t figured out how to factor it nicely. With others they are abstracted.

TL: in the implementation it’s a bit messy to check both at once, agreed. They are essentially privileged fields. But they relationships that they form when they satisfy the constraints are the same as the ones you can create with fields already. In this example you get the same relationships. Sub.desc is only a subtype of super.desc if sub is a subtype of super. It’s less clean but there’s no extra power in the type system. We agreed when we discussed that.

AR: agreed that it’s’ doable but its still unclear how to factor in the spec, which suggests that there’s still something fundamental there. So i’m not convinced yet that you can completely compare those. Maybe we’ll find a way to express it better but it’s still a concern.

TL: figure reified RTTs. there is room for that in the future if we want it

Open questions: IMO we should rename ref.cast_desc to ref. cast_desc_eq

V8 can support descriptors of descriptors because maps can have meta-maps. But Ryan says it's harder in spidermonkey. So it would simplify at least one implementation if we don’t allow that.

Should we split JS interop out from the proposal? Sheets would be happy about that, to get memory savings sooner, maybe it would be simpler for other implementations?

CW: on thought on that: I do think the performance and footprint numbers here aren’t really that exciting for the complexity, but there were several defenses by toolchains on ergonomics for targeting wasm. So I would feel better with the proposal if it was motivated by the JS interop use cases.

TL: yes, the benefit comes from the JS interop. But the JS interop portion is still  WIP in terms of the toolchain side. J2Wasm is building out their JS interop story on top of this still, but the CD part is ready to go out the door. Don't have a strong opinion on whether to split. Shouldn't decide today, but should keep considering.

I don’t think the open questions should block phase 3.

CW: I do have a reasonably strong negative opinion that I wouldn’t want this proposal to move forward without JS interop, just too much complexity for the benefit.

TL: to be clear, it’s still one piece as moving forward today.

RH: that’s fine with me. I also wouldn’t want to move to phase 4 with JS interop unless we see toolchain support to validate that. So if it stays in phase 3 until that happens, thats ok

TL: I think today we have high confidence that this is the JS interop extension we want. Modulo a few small questions. We’re still just waiting for toolchain to try it out. So we want to validate for that before phase 4, but high confidence that it’s just engineering at this point.

NF: has anyone else been implementing this, and can speak to the complexity of the language changes?

RH: we have patches with a partial implementation. They haven’t gotten too far yet. The validation rules have me scratching my head to think through all the edge cases with describes/descriptors. Even the terms are similar! But don’t have the result from putting full effort into it. Sometimes after you work through the details you find it wasn’t so bad.

NF: is this in SM itself now, or just those wasm-tools patches I saw?

RH: wasm-tools patches, and also some WIP/ not yet reviewed patches for spidermonkey

TL: Phase 3 requirements slide

Poll Advance Custom Descriptors proposal to phase 3?

| SF | F | N | A | SA |
| - | - | - | - | - |
| 8 | 14 | 12 | 0 | 0 |

CW: Poll passes, CD to phase 3. There are a lot of N votes, would people be ok with a straw poll on whether you’d be comfortable advancing without JS?

TL: Now or for the future?

CW: for future. Phase 3 passes as-is.

Informal/Straw poll: Would you support this proposal moving to phase 4 without JS interop?

| F | N | A |
| - | - | - |
| 7 | 18 | 2 |

AR (chat): @Jakob Kummerow, do you have an example of a type where the possibility of merging is lost when using CD? I assume if two types happen to have identical vtables?

JK (chat): I don't know of a concrete example, but perhaps @Thomas Lively does

TL (chat): @Andreas Rossberg, see this test where the descriptors cannot be merged due to casts, preventing the described types from being merged: https://github.com/WebAssembly/binaryen/blob/main/test/lit/passes/type-merging-desc.wast#L246-L286 

AR(chat): @Thomas Lively, I see, though if the descriptor is used for casts, what would be the equivalent without CDs? 


#### Advance `Rounding Variants` to Phase 3 (Paul Dennis, 30 minutes)

PD Presenting (TODO link)

PD shows rounding-variants.wast test suite

JK (chat): To clarify: these V8 patches are in some private fork, right?

CW: do you have any signal from e.g. V8 whether they’d accept patches for this?

PD: there was an issue in the tracker, that if there was a patch that was high enough quality, they’d consider merging it.

CW: Any V8 people who have seen this and have any opinions?

PD: the fork is published but haven’t interacted with the team yet.

AR: You have implemented all 4 rounding modes for all instructions? How many opcodes altogether?

PD: 3 new modes, a total of 60 instructions. Currently 3-byte representation, about half a percent in the 0xfc space

AR: Why only 60? Every type and every rounding mode?

PD: just + , - mul, div, sqrt, 10 x 3 is half. Then conversions. Only from int to float, but not float to int, for those you can use ceil and floor functions and then convert.

AR: but there are multiple int and float types.

PD: one rounding variant would be 20 instructions if i counted correctly.

AR: I’ll check the proposal. We have a lot of arithmetic  instructions for every type.

PD: not all have hardware support. These are just the ones that do.

AR: would we eventually need this for SIMD as well?

PD: I’m concerned about the use case of interval arithmetic. You could theoretically use it for SIMD, but from that use case SIMD isn’t needed. I wouldn’t recommend doing it.

DS: is there also hardware support for SIMD?

PD There is, but there are  also workarounds in userland. You can take a 16 bit float then convert to higher precision, do your instruction there and round it back. It works for the 3 nonstandard rounding variants.

AC (chat): If I recall correctly one of the motivations for this proposal was performance, and assuming I’m remembering right are there any numbers/measurements about the implementations you’ve done?

PD: (link to issue 2 in rounding-mode-control) was about 3.7x faster to do it with native compared to doing it in userland in the benchmark.

CW: is this a microbenchmark?

PD: it runs a big test suite of instructions, through all the modes, and measures how long it takes.

CW: is this workload testing the instructions in a loop, or an end to end application that requires the rounding mode computations?

PD: a JS loop with the data in an array and calls into wasm and runs the instruction. Runs for each implementation.

BT: on the emulation. Is that ahand-tuned asm, or C or what?

PD: implementation in haskell that has high-level support for rational numbers. Internally it uses a big integer implementation, using int instructions to emulate a big FP number.

BT: is there a link to that code in the issue?

PD: yes, a link in the Dec 7 comment. I’ll add a more direct one.

CW: a higher level point: i do think this proposal has satisfied the on-paper requirements. If we want to move though, i want to see some buy in from the implementers. And I odn’t see that yet, we’ve seen silence from the engines. Is there any positive signal from them?

TL: there are requests from the V8 to actually see the patch.

JK (chat): I'd like to see a benchmark that compares the same workload on Wasm with and without this proposal

PD(chat): https://gitlab.com/pauldennis/v8-rounding-fiasco/-/compare/326f5f8cad3f0e436c8ea8f82a6894936a32e860...5a9c3b84d62a7bf75661eba5e018b2da5165fe2f?from_project_id=71766202

EZ (chat): Also, the test harness seems to dominate over the actual measurement of hte instructions from the description that we got. It would be good to also see the source code of the benchmark.


CW: is the issue that the test harness was in JS: or just that we’ve not looked lcosely enough at what’s been done.

JK: AFAIU those numbers use some kind of haskell emulation that didn’t sound really comparable. I would like to see some kind of real workloads, e.g. libraries that do interval arithmetic, they could be compiled to wasm, right? It would be nice to compare what you’d have to do in wasm today for a given work load vs how much faster it would be if you had the instructions. There are a lot of things you could add to wasm, but its hard to spend the time without seeing concrete benefits.

PD: I’m not aware currently of any implementation. The haskell one is the only one I know for webassembly.

TL: that was haskell compiled to wasm right? So it was a wasm workload against the wasm workload with the proposal. Sounds like it was very high level though?

PD: it was all done in the browser, yes.

DG: I think the general theme of these comments is that even if you don’t have a full app, just knowing how hard to emulate in wasm it would be. How would you actually emulate it, and how does it make it better? E.g. if you know what parts of the codegen go away, or a bit more of a with/without comparison, even if it’s not a full benchmark

CW: anyone who’d be willing to volunteer to talk through with Paul on what kind of benchmarks or toolchain engineering you’d want to see?

DG: I can talk in terms of benchmarks, not sure about tools.

TL: I’m happy to chat about that as well.

CW: I’m not seeing a lot of support in the room, I think we should maybe postpone the phase 3 for now. We should talk more about what the implementers want to see.
I do think you’ve done good work here, but at the end of the day we want to be sure the implementers are going to adopt it if we standardize it, so I think we want to work on that.

PD: yes i’m definitely willing to work with them on that

CW: you should also be proactive, it would help to contact them

BT: one way to get a bit more buy in could be a wasm polyfill for the instructions you’re proposing. They could be adopted by interval arithmetic libraries, and then you could directly compare.

PD: the benchmark was done with 2 wasm modules. One with the native instruction and one where every export was one instruction.

CW: can you look at the benchmark then and see if it looks like what you’re wanting?

BT: yes I can do that.

CW: I think the path forward is some more dialog with the champion and the implementers

### Closure
