![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the March 15th video call of WebAssembly's Community Group

- **Where**: zoom.us
- **When**: March 15th, 4pm-5pm UTC (March 15th, 9am-10am Pacific Time)
- **Location**: *link on calendar invite*

### Registration

None required if you've attended before. Send an email to the acting [WebAssembly CG chair](mailto:webassembly-cg-chair@chromium.org)
to sign up if it's your first time. The meeting is open to CG members only.

## Logistics

The meeting will be on a zoom.us video conference.
Installation is required, see the calendar invite.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking (acting chair to volunteer)
1. Adoption of the agenda
1. Proposals and discussions
    1. Update on [Extended Const Expressions](https://github.com/WebAssembly/extended-const) (Sam Clegg) [10 min]
        1. Poll to Phase 2 or Phase 3
    1. Phase 1 poll for a split-off WasmGC JS Customization proposal (Thomas Lively) [5 min]
    1. Discussion on [Feature Detection](https://github.com/WebAssembly/feature-detection/blob/main/proposals/feature-detection/Overview.md) (Thomas Lively) [45 min]
        1. [How should features be specified?](https://github.com/WebAssembly/feature-detection/issues/3)
        1. [What features should be specified?](https://github.com/WebAssembly/feature-detection/issues/4)
        1. [Should feature detection be decode-only?](https://github.com/WebAssembly/feature-detection/issues/2)
        1. Possible poll to phase 2
1. Closure

## Agenda items for future meetings

*None*

### Schedule constraints

*None*

## Meeting Notes

### Attendees
* Derek Schuff
* Yuri Iozelli 
* Bailey Hayes
* Frank Denis
* George Kulakowski
* Yury Delendik
* Jeff Charles
* Saul Cabrera
* Sam Clegg
* Conrad Watt
* Thomas Lively
* Francis McCabe
* Luke Wagner
* Jay Phelps
* Lars Hansen
* Paolo Severini
* Rick Battagline
* Alex Crichton
* Zhi An Ng
* Ryan Hunt
* Chris Fallin
* Jakob Kummerow
* Michał Kawalec
* Manos Koukoutos
* Andrew Brown
* Ben Titzer
* Adam Klein
* Mingqiu Sun
* Jacob Abraham
* Ioanna Dimitriou
* Emanuel Ziegler
* Dan Gohman
* Richard Winterton
* Asumu Takikawa
* Andreas Rossberg
* Jonnnie Birch
* Zalim Bashorov


### Update on [Extended Const Expressions](https://github.com/WebAssembly/extended-const) (Sam Clegg) [10 min]

SC presenting [slides](https://docs.google.com/presentation/d/1tjxc_pLa86YhjtR7NjWskHjC--C8JhyaEjkYpEQCtiI/edit#slide=id.gc6fa3c898_0_0)

CW: what’s the situation with the test suite right now? 

SC: It has some tests that I wrote. In V8, the implementation is just C code rather than using the VM’s existing codegen. I’m not sure if we want to try to exercise the same edge cases we currently test for regular instructions, since it’s basically a different implementation. 

So we could go straight to phase 3 since we have tests and implementations

DS: Have we tried 64 bit memories with this proposal?


SC: Not yet, no. First end-to-end test done yesterday. Different implementations have implemented this differently. For example WABT uses its normal interpreter.

AR: My only suggestion to add would be conversion for i32/i64. It could come up if you’re mixing 32-bit code, especially with address spaces. They can’t trap, right? It seems easy to add.

SC: Yeah, we can do that. Wouter suggested it too


POLL for phase 3:
SF: 9
F: 18
N: 2
A: 0
SA: 0



### Phase 1 poll for a split-off WasmGC JS Customization proposal (Thomas Lively) [5 min]


TL: The GC subgroup voted to defer a “rich” JS API, where “rich” means you can attach custom methods, accessors, prototypes, JS Stuff to GC objects. We were considering that but decided to defer that to a followup proposal. We have a phase 0 repo for that, called gc-js-customization. We just wanted to get an official vote to move it to phase 1. Entry requirements are that we agree that this is within scope and worth solving.

SC: That means that if you have a GC object and you try to get a property that’s not there, it traps?


TL: yeah either trap, or throw some kind of exception (type error?). SO we aren’t completely deferring any kind of JS API. we’ll have something and it will be well-specified. But the way you interact with the objects will be via imported/exported functions.

TL: the champion will be Asumu

TL: we can do a consensus poll, I haven’t heard any concerns on this.

Consensus poll: any objections to phase 1 for gc-js-customization?

No objections, poll passes.


### Discussion on [Feature Detection](https://github.com/WebAssembly/feature-detection/blob/main/proposals/feature-detection/Overview.md) (Thomas Lively) [45 min]

[slides](https://docs.google.com/presentation/d/1UlwhMEpmIubwBRoF31l9QMoUJsxkgcypygveiu5LV0U/edit?usp=sharing)

AR: can you clarify what you mean by saying SIMD users are “used to” having feature detection?

TL: the mechanism they’re used to queries the CPUID (e.g. cpuinfo) and tells whether features are present. So they query whether the CPU cupports instructions xyz. If so, go down this codepath that uses those instructions, otherwise fall back to one that doesn’t. In clang and gcc, there’s a compiler extension that you can use to make this easy where you define multiple versions of the same function, with an attribute that says which hardware features each version requires, and the compiler can generate code that switches between the versions depending on the features. So we hope to implement that extension using this proposal.

AR: did we ever explore the possibility of restricting conditional sections such that they are required to produce sections with the same type and size, which would fix this issue (unstable indices)

TL: I think it was raised as something to maybe look at, but ultimately would be more complexity on the conditional sections. Now you have some sort of type or size for the section itself.

AR: we currently have that, every section has size. There is a lot of discussion about complexity here, I believe that the current proposal down the road will be way more complicated.

TL: it’s a little bit a matter of taste. You said that the new proposal is ad-hoc. But I would say that adding side conditions on sections re: the size is rather ad-hoc. So I guess there’s different valid ways of looking at the complexity here.

FM: don't think having a constraint on the conditional sections would work, if you have to replace implementation of SIMD or something else, will have different number of functions there

AR: that was the argument at the time but the current proposal has even stricter restrictions. It would certainly subsume what we have in the current proposal.

BT: one argument for having indices match up, you can save work. if they are validated and don't reference conditionally defined things, they would still be valid.

AR: maybe we should postpone this discussion until after the presentation?

FM: is there a negated version of that? This rewrites to a block if feature is there. What about if feature is not there, for feature block.

TL: it becomes unreachable. For the opposite. Can't think of what's useful, you always check for features before using instructions, can't think of where you want to check for absence of features

BT: you could provide an alternative implementation when the feature is missing, feature_block, else.

TL: I see. So building the alternative block body into the same construct. That would be possible. I’m not sure it would be any simpler for code generators, but might be worth looking into.

JB: Is it possible that an engine could skip(?) validating code but then somehow still execute it?

TL: this is all resolved at decode time, before validation. So after decode you end up with only instructions and types that the engine can validate. So there are no changes to validation here. If you end up with an instruction that the engine doesnt understand after decode you still have a validation failure

FM: how does this interact with code annotations?

TL: that works via byte offsets into the code section, so because this is not instruction count, but not byte offsets, it is stable, no matter what the feature set ends up being.

FM: thought it was relative to function?

TL: yes, it is. All of these only appear in functions, so the byte count is still stable. So I think that should just work.

FM: even though this is resolved at decode time, the byte offsets persist after decoding?

TL: yes. E.g. if I attach an annotation to the middle of the feature block; if the features are supported they attach to whatever instruction it is. If the feature is not supported, then the feature block becomes a long encoding of unreachable, and the annotation just points to the middle of this long unreachable instruction. I don’t remember what we specified a code annotation to mean if it points to the middle of an instruction.

YI: for branch hinting, spec says that it's wrong to have annotation attached to something that is not a branch instruction, we are considering relaxing this to say to do nothing if not attached to a branch instruction.

CW: more generally we decided that invalid custom sections can’t result in errors.

YI: right but we did decide that the engine stops processing hints if it finds an invalid one. So we could change that.

CW: not observable either way, will still be safe if engine gives up on processing future hints or not

LW: even in longer term, if everyone implemented this, this feature can support instructions not being optimized for the hardware. Is that a use case that also matters?

TL: yeah i could definitely see that working. It would be a little tricky because you want to differentiate those use cases. If you have the same features and one producer is interpreting the presence as “validates and is fast” and the other is “validates but I don’t know if this is fast” then…

LW: scoping to SIMD makes sense, a lot of value in supporting these use cases. Seems like the need to do at decode type and unknown bytes, if you can support the feature and be unoptimized, it's a low effort.

TL: yeah this is getting back to your suggestsinos from conditional sections too. My concern there is that there’s already such limited bandwidth to update all th engines in the ecosystem. The motivation to support a performance-oriented proposal that won’t be fast. The effort even just to support and validate all the instructions, would that be there?

BT: in the middle of implementing SIMD in an engine that won't optimize it very well. If feature block has features.is_fast, easy for me to say not fast.

LW: can say that they are slow, and trap if you try running them

TL: I think that would work. It would certainly be useful to be able to detect whether they’d be optimized or not. What would you say the advantage is, having them validate, over having the instructions being skipped over by the decoder?

LW: generic fear that this becomes how non standard features get shipped

CW: that’s my fear too.

BT: in wizard, unlikely will emit Intel instructions to make this fast, polyfill, will be 100x slower. Having this feature will probably make applications a lot faster, they can use scalar code.

CW: you could still essentially lie, and say you don’t support SIMD at all, but if someone gives you a module that only has SIMD you could still run it.

BT: definitely a gray area

TL: we can have is_fast be a separate feature from is_supported, or you can lie about support. few options, worth discussion offline. A lot of utility to tell if SIMD will be fast. For non-standard instructions fear, if anyone want's to implement them, this will be a good way to get it in. Non-standard instructions are already possible, just have a new opcode prefix, no one has done that yet.

LW: it’s not been done because it’s not practical, you can’t ship that code anywhere

LH: you can't ship it very many places

TL: how much do we have modules being use portably across engines at all so far? One end-to-end provider with toolchain + engine can do whatever they want already but we haven’t seen that. But yeah it’s a valid fear and this would lower the bar to adding nonstandard stuff. Given that nobody had done this already, I do wonder if they would.

BT: recent thread about versions and version 1.0 and ecosystem, some discussion there. Talked about profiles, we need a larger discussion and plan overall. Conditional sections is part of that, at least some document of what we're going to do versioning wise.

CW: speaking of, if we do end up with conditional sections, is the mechanism kind of married to feature testing or are they totally separate things?

TL: won't want to commit up front being the same, I want to scope this to SIMD. Conditional sections will necessarily be much more general.

CW: my immediate concern is, it seems like you’ll end up needing conditional type sections too. There are too many situations where you want to swap out a function and need a type annotation, so it ends up just looking like conditional sections

TL: in producers, LLVM especially, this scoped down feature detection will be way easier to emit than conditional sections.

CW: will be reassured by binaryen people saying we are not so worried about type annotations

TL: for types, it should mostly just be in locals, in code section. The feature type thing, would work in the type section, no reason to prohibit it in type section, don't think it would need to. In practice most SIMD functions don't take SIMD types, take pointers to memory, and loop over that.

CW: if you wanted to take advantage of that you’d have to have no functions taking or producing SIMD

TL: you could use the feature type thing, even in the type section. It would have large code size overhead, so will want to minimize that.

AR: im not sure that’s enough. If you have a function and want to switch between SIMD and non, you might have one SIMD vs 3 i32 params, which isn’t something you can express this way.

TL: in pratice, you take a pointer to memory, this would never come up.

AR: famous last words, don't think I buy that. In combination with GC proposal, struct with SIMD type, array of i32. Current thing won't scale.

CW: even if naturally generated code doesn’t end up with  SIMD in arguments, you can imagine optimizations hosting the values directly into arguments.

AR: generally deeply concerned that this is considering too narrow use case, not scaling well, and at the same time very intrusive, not a simple feature.

TL: how do you mean intrusive? You mean that it only applies to decoding?

AR: for one, it makes decoding non deterministic, changes one fundamental property of the language. Fear it will be a rabbit hole, will add more conditionals to grammatical phrases of the language, very cross-cutting. Whereas something like conditional section creates a separate layer where all this is handled, without adding separate things to handle everywhere. More modular and scalable in that way.

DS: conditional sections for SIMD, what you want in SIMD is hve 90% of code be the same, only 10% different. A conditional code section will have SIMD and duplicated non-SIMD, even though most of it is the same.

AR: part of the proposal is that you can have multiple sections, only part of it duplicated. My abstract feeling is that this is trying to bring a form of meta programming to the language, a bit of a smell to mix meta programming with the programing layer.

FM: I have a slightly different followon: Ben said he’s currently implementing SIMD poorly. If he wants his engine to be competitive, he’ll have to implement it properly. That’s true for all engines and features: developers will be motivated to implement the whole language. For long term I don’t see an advantage for a developer to not implement the features.

BT: The issue is that some hardware just doesn’t have SIMD instructions, e.g. embedded systems. Best you can do there is scalar code, so it would be better to have the module use originally scalar code.

CW: I would be convinced by that if we believe that on average would be much slower. But if it can be made about the same then it wouldn’t be a problem.

TL: IME emulation is usually slower than a good scalar version by the application

BT: for f32x4 it's a toss up, i8x16 will be slower for engine to scalarize.

AR: engines have to be more strict, producers have more leeway, if compiling from C, more ways to optimize

BT: for i8x16, have to unpack and repack it every time, can't see beyond a single instruction, want static compiler to avoid unpack and repacking.

CW: given that we’re getting close to time and will discuss more i’d be interested to see a version of condition sections where we restrict based on the index spaces as we discussed.

TL: action items, work through conditional sections for that restriction, file issue on this proposal for detecting is_fast rather than just if it’s supported.

For folks with even vague concerns about the direction here, it would be really helpful to get those in the form of issues, even if it’s just “i don’t like this proposal, it’s too narrow” would be great to hear.

