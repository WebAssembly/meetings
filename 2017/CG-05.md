![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the May meeting of WebAssembly's Community Group

- **Host**: Google, Mountain View, CA
- **Dates**: Tuesday-Wednesday May 30-31, 2017
- **Times**:
    - Tuesday - 9:00am to 5:00pm
    - Wednesday - 9:00am to 5:00pm
- **Location**: 1881 Landings Dr, Mountain View, CA 94043
- **Wifi**: GoogleGuest (no password)
- **Dinner**:
   Tenative: [Stein's Beer Garden](http://steinsbeergarden.com/)
   Please sign up for dinner [here](https://goo.gl/FCh9eP).

- **Contact**:
    - Name: Brad Nelson
    - Phone: +1 650-214-2933
    - Email: bradnelson@google.com

### Registration

Please register before the event [here](https://goo.gl/forms/LQVhuRuI22lK8Umw1).

## Logistics

* Where to park
  - Free parking is available outside the building.

* How to access the building
  - The morning of event we'll meet you at the door.
  - At other times, please call or email the host.

* Technical presentation requirements (adapters, google hangouts/other accounts required, etc.)
  - Presentations will be done with a Google Hangout.
  - Contact host if you need alternatives.

* Any other logistics required to participate in the meeting
  - Please register before the event
    [here](https://goo.gl/forms/LQVhuRuI22lK8Umw1)
    as we may not be able to accommodate late arrivals.

### Hotels

[Nearby Hotels](https://www.google.com/maps/search/Hotels/@37.4199107,-122.0963779,15z/data=!3m1!4b1!4m8!2m7!3m6!1sHotels!2sMTV-LMK2,+1881+Landings+Dr,+Mountain+View,+CA+94043!3s0x808fba03c5d4f8d3:0xeeec4f675931b927!4m2!1d-122.0876231!2d37.4199111)

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
    1. Host facilities, local logistics
1. Find volunteers for note taking
1. Adoption of the agenda
1. Proposals and discussions
    1. Working Process
    1. Threads (Ben Smith)
       * [Proposal](https://github.com/WebAssembly/threads/blob/master/proposals/threads/Overview.md)
       * Brief overview of the proposal
       * Topics for committee feedback
         - [i8 and i16 Value Types](https://github.com/WebAssembly/design/issues/1049)
         - [Encoding Scheme](https://github.com/WebAssembly/threads/issues/12)
         - [Matching SharedArrayBuffer/Atomics for v1](https://github.com/WebAssembly/threads/issues/5)
         - [Float atomics](https://github.com/WebAssembly/threads/issues/7)
         - [i64 atomics](https://github.com/WebAssembly/threads/issues/7)
         - [i64.wait](https://github.com/WebAssembly/threads/issues/7)
         - [Is the set of proposed instructions sufficient?](https://github.com/WebAssembly/threads/issues/11)
         - [Blocking main thread in web embedding](https://github.com/WebAssembly/threads/issues/6)
         - [Thread-local and Shared Global variables](https://github.com/WebAssembly/threads/issues/4)
         - [Consider supporting verifiably safe concurrency](https://github.com/WebAssembly/threads/issues/3)
         - [Native WebAssembly threads - needed for v1?](https://github.com/WebAssembly/threads/issues/8)
         - [Memory model standardization](https://github.com/WebAssembly/threads/issues/9)
         - [Memory orderings - sequential consistency only?](https://github.com/WebAssembly/threads/issues/13)
         - [How to test?](https://github.com/WebAssembly/threads/issues/10)
    1. Non-trapping float-to-int conversions [[1](https://github.com/WebAssembly/design/issues/986),[2](https://github.com/WebAssembly/meetings/pull/3#issuecomment-302154544)] (Dan Gohman) : 30 minutes
    1. SIMD (Jakob Stoklund Olesen)
       * [Proposal](https://github.com/WebAssembly/simd/blob/master/README.md)
       * Brief overview of the proposal
       * Topics for committee feedback
         - [SIMD types and basic operations](#simd-types-and-basic-operations)
         - [SIMD binary encoding](#simd-binary-encoding)
         - [Allow flushing of subnormals in floating point SIMD operations](#allow-flushing-of-subnormals-in-floating-point-simd-operations)
         - [Reciprocal (sqrt) approximation instructions](#reciprocal-sqrt-approximation-instructions)
         - [Alternative to Swizzle / Shuffle](#alternative-to-swizzle--shuffle)
       * Definition of performance benchmarks and acceptance criteria
    1. Working Group Formation
        * [Draft charter](https://webassembly.github.io/wg-charter/webassembly-wg-charter.html)
1. Closure

### Schedule constraints

## Dates and locations of future meetings

| Dates                    | Location          | Host       |
|--------------------------|-------------------|------------|
| 2017-07-17 to 2017-07-19 | San Francisco, CA | Google     |
| 2017-11-06 to 2017-11-07 | Burlingame, CA    | TPAC       |

## Proposal details

### Threads proposal details

#### i8 and i16 Value Types

Tracking Issue: [i8/i16 values with limited operators #1049](https://github.com/WebAssembly/design/issues/1049)

**Poll**:

> Add `i8` and `i16` value types.

Adding i8 and i16 value types can reduce the number of opcodes required to
implement atomics. Because they were not considered for the initial WebAssembly
design, adding them now introduces some potential inconsistencies.

#### Encoding Scheme

Tracking issue: [Encoding Scheme #12](https://github.com/WebAssembly/threads/issues/12)

**Poll**:

> 1. Use `0xf0` prefix byte for all threading opcodes.
> 2. Use `0xff` prefix byte for all threading opcodes.

This should be coordinated with the SIMD proposal.

**Poll**:

> 1. Encoding proposal #1: No new non-atomic operators. Add 107 new atomic operators.
> 2. Encoding proposal #2: Use i8 and i16 value types. Add 12 new conversion operators. Add 40 new atomic operators.
> 3. Encoding proposal #3: Add 5 new sign-extend operators. Add 67 new atomic operators.

See the full description of these proposals in the [overview](https://github.com/WebAssembly/threads/blob/master/proposals/threads/Overview.md).

#### Matching SharedArrayBuffer/Atomics for v1

Tracking issue: [Matching behavior of SharedArrayBuffers in ES spec #5](https://github.com/WebAssembly/threads/issues/5)

**Poll**:

> Include the same atomic and threading primitives as provided by the ES spec.

This includes:
* `is_lock_free`
* `wait` for 32-bit integers
* `wake`
* Atomic ops for 8-, 16-, and 32-bit signed and unsigned integers:
  - `load` and `store`
  - `add`, `sub`, `and`, `or`, `xor`, `xchg`
  - `cmpxchg`

#### Float atomics

Tracking issue: [float atomics, i64 atomics, i64.wait #7](https://github.com/WebAssembly/threads/issues/7)

**Poll**:

> Include `f32` and `f64` atomic `load` and `store` operators.

These are not currently included in the ES spec. Similar functionality is
proposed for C++20.

#### i64 atomics

Tracking issue: [float atomics, i64 atomics, i64.wait #7](https://github.com/WebAssembly/threads/issues/7)

**Poll**:

> Include `i64` atomic `load`, `store`, and `rmw` operators.

These are not currently in the ES spec.

#### i64.wait

Tracking issue: [float atomics, i64 atomics, i64.wait #7](https://github.com/WebAssembly/threads/issues/7)

**Poll**:

> Include `i64.wait` operator.

This is not currently in the ES spec. It is included in the proposal because it
is symmetric (`i32.wait` atomically loads a 32-bit value), but it is not clear
whether it is useful.

#### Is the set of proposed instructions sufficient?

Tracking issue: [Is the set of proposed instructions sufficient? #11](https://github.com/WebAssembly/threads/issues/11)

Discussion: are there further atomic/threading operations that should be included?

* `pause` ([spinloop relaxation instruction](https://github.com/WebAssembly/threads/issues/15))

#### Blocking main thread in web embedding

Tracking issue: [Blocking the main thread in web embedding #6](https://github.com/WebAssembly/threads/issues/6)

**Poll**:

> `*.wait` instructions may trap when executed in certain contexts (e.g. main thread in web embedding).

This was required for the ES spec. The specific contexts depend on the
[`[[CanBlock]]` property](https://tc39.github.io/ecma262/#sec-agents) of the
agent.

#### Thread-local and Shared Global variables

Tracking issue: [What are the plans for thread-local and shared global variables? #4](https://github.com/WebAssembly/threads/issues/4)

Discussion:

Globals currently cannot be imported or exported if they are mutable.

Globals could be used to implement the C/C++ stack pointer, but cannot be dynamically
linked if mutable globals cannot be imported/exported. This can be worked around by 
using linear memory instead.

When linear memory is shared, there is no way to implement dynamically linked
thread-local variables: globals cannot be used because they cannot be exported, and
linear memory cannot be used because it is shared.

Should we implement mutable globals as thread-local values? Should the threading
proposal depend on this?

#### Consider supporting verifiably safe concurrency

Tracking issue: [Consider supporting verifiably safe concurrency #3](https://github.com/WebAssembly/threads/issues/3)

Discussion: is there some subset of WebAssembly that can be provided for verifiably
safe concurrency?

#### Native WebAssembly threads - needed for v1?

Tracking issue: [Native WebAssembly threads #8](https://github.com/WebAssembly/threads/issues/8)

**Poll**:

> Add "native" threads to WebAssembly, in addition to embedder-created threads, for v1.

The current proposal has no mechanism for creating or joining threads, relying on
the embedder to provide these operations. This allows for simple integration with
SharedArrayBuffer, where a dedicated worker is used to create a new thread.

There is a drawback for WebAssembly, as a worker is a relatively heavyweight
construct, and a native thread would be considerably more lean.

#### Memory model standardization

Tracking issue: [Memory model standardization #9](https://github.com/WebAssembly/threads/issues/9)

**Poll**:

> Is the memory model document required before merging the threads proposal?

It's assumed the memory model document is needed, this question is asking when.

**Poll**:

> 1. Reference ES memory model, with WebAssembly-specific modifications.
> 2. Create a shared memory model document that can be referenced by both ES and WebAssembly.
> 3. Create an independent memory model document for WebAssembly.

#### Memory orderings - sequential consistency only?

Tracking issue: [Memory ordering - Sequential Consistency only? #13](https://github.com/WebAssembly/threads/issues/13)

**Poll**:

> Provide only sequentially-consistent atomic operators for v1.

#### How to test?

Tracking issue: [How to test? #10](https://github.com/WebAssembly/threads/issues/10)

Discussion:

What tests will we want for WebAssembly threads?

* wait/wake
* Memory sharing
* Atomic API
* Atomicity?
* Ordering constraints?

### SIMD proposal details

#### SIMD types and basic operations

Tracking issue: [Initial Proposal #1](https://github.com/WebAssembly/simd/pull/1).

The SIMD proposal uses a single `v128` value type to represent a 128-bit SIMD
vector.

**Poll**:

> Adopt a `v128` value type along with basic operations `v128.const`,
> `v128.load`, `v128.store` as well as bitwise logic instructions `v128.and`,
> `v128.or`, `v128.xor`, and `v128.not`.

Predicate vectors are represented with separate value types that don't have an
in-memory representation. This allows implementations to choose their own
representation. The `v*.select` operations are the primary consumers of
predicate vectors.

**Poll**:

> Adopt the `b8x16`, `b16x8`, `b32x4`, and `b64x2` value types along with the
> basic operations `b*.const`, `b*.splat`, `b*.extract_lane`,
> `b*.replace_lane`, as well as the logical operations `b*.and`,
> `b*.or`, `b*.xor`, `b*.not`, and `v*.select`.

Floating-point arithmetic is supported by the `f32x4.*` and `f64x2.*`
operations. The inclusion of `div` and `sqrt` will be discussed later, as will
the handling of subnormal numbers.

ARMv7 NEON supports `f32x4` arithmetic with subnormal numbers flushed to zero
only, and `f64x2` operations must be implemented with pairs of scalar VFP
instructions.

**Poll**:

> Adopt the following `f32x4.*` operations:
>
> - Basics: `f32x4.{splat,extract_lane,replace_lane}`.
> - Comparisons: `f32x4.{eq,ne,lt,le,gt,ge}`.
> - Arithmetic: `f32x4.{neg,abs,min,max,add,sub,mul}`.

**Poll**:

> Adopt the following `f64x2.*` operations:
>
> - Basics: `f64x2.{splat,extract_lane,replace_lane}`.
> - Comparisons: `f64x2.{eq,ne,lt,le,gt,ge}`.
> - Arithmetic: `f64x2.{neg,abs,min,max,add,sub,mul}`.

Small integer arithmetic is provided by the `i8x16.*`, `i16x8.*`, and
`i32x4.*` operations. These operations are widely supported by both Intel and
ARM ISAs. Integer division is not included since it is not widely supported.

**Poll**:

> Adopt the following `i8x16.*`, `i16x8.*`, and `i32x4.*` operations:
>
> - Basics: `{i8x16,i16x8,i32x4}.{splat,extract_lane*,replace_lane}`.
> - Arithmetic: `{i8x16,i16x8,i32x4}.{add,sub,mul,neg}`.
> - Shifts: `{i8x16,i16x8,i32x4}.{shl,shr_s,shr_u}`.
> - Equalities: `{i8x16,i16x8,i32x4}.{eq,ne}`.
> - Inequalities: `{i8x16,i16x8,i32x4}.{lt,le,gt,ge}_[su]`.

The `i64x2` operations are more limited, but they are still useful for bitwise
manipulation of `f64x2` vectors. Division and multiplication are not widely
available. Comparisons exist in SSE 4.2 and ARMv8 only.

**Poll**:

> Adopt the following `i64x2.*` operations:
>
> - Basics: `{i8x16,i16x8,i32x4}.{splat,extract_lane*,replace_lane}`.
> - Arithmetic: `{i8x16,i16x8,i32x4}.{add,sub,neg}`.
> - Shifts: `{i8x16,i16x8,i32x4}.{shl,shr_s,shr_u}`.

64-bit comparisons will be slow on ARMv7 and Intel chips without SSE 4.2.

**Poll**:

> Adopt the following `i64x2.` operations:
>
> - Equalities: `{i8x16,i16x8,i32x4}.{eq,ne}`.
> - Inequalities: `{i8x16,i16x8,i32x4}.{lt,le,gt,ge}_[su]`.

The 64-bit multiplication is implemented in AVX-512, but would be slower
everywhere else. All ISAs have 32 x 32 â€“> 64 multiplies (`pmuludq`, `umull`) that
can be used to implement this operation.

**Poll**:

> Adopt the `i64x2.mul` operation.

Saturating integer arithmetic is widely available for 8-bit and 16-bit lanes,
but not for `i32x4`.

**Poll**:

> Adopt the saturating integer arithmetic operations
> `{i8x16,i16x8}.{add,sub}_saturate_[su]`.

Integer-to-float conversions are always non-trapping.

**Poll**:

> Adopt the `f*.convert_[su]/i*` integer-to-float conversions.

When converting floating-point numbers to integers, we can choose to trap or
saturate on overflow.

**Poll**:

> Adopt the trapping `i*.trunc_[su]/f*` float-to-integer conversions.

**Poll**:

> Adopt the saturating `i*.trunc_[su]/f*:sat` float-to-integer conversions.


#### SIMD binary encoding

Tracking issue: [SIMD binary encoding #14](https://github.com/WebAssembly/simd/issues/14).

The current SIMD proposal defines 193 new operations, and it is likely that
more SIMD operations will be added in the future. We need an extensible way of
encoding the opcodes for these operations.

**Poll**:

> SIMD opcodes are encoded as `0xf1 varuint32`, where `0xf1` indicates a SIMD
> operation and the `varuint32` number identifies the specific operation.

This should be coordinated with the [threads proposal](https://github.com/WebAssembly/threads/blob/master/proposals/threads/Overview.md)
which currently uses a `0xf0` prefix byte followed by an opcode byte in the
range `0x00 - 0x7a`.

The new value types also need assigned numbers.

**Poll**:

> Assign the following numbers to the new SIMD value types:
>
> - `0x7b => v128`
> - `0x7a => b16x8`
> - `0x79 => b8x16`
> - `0x78 => b4x32`
> - `0x77 => b2x64`


#### Allow flushing of subnormals in floating point SIMD operations

Tracking issue: [Allow flushing of subnormals in floating point SIMD operations #2](https://github.com/WebAssembly/simd/issues/2).

ARMv7 NEON devices support `f32x4` arithmetic, but only with subnormals flushed
to zero. On these devices, `f64x2` arithmetic needs to be implemented with the
slower VFP instruction set which does support subnormals correctly, so the
problem only applies to `f32x4` operations.

**Poll**:

> Adopt the proposed specification text which allows SIMD floating-point
> instructions to flush subnormals to zero.


#### Reciprocal (sqrt) approximation instructions

Tracking issues: [Implementation-dependent reciprocal (sqrt) approximation instructions #3](https://github.com/WebAssembly/simd/issues/3) and [Eliminate divide, square root #13](https://github.com/WebAssembly/simd/issues/13).

Floating-point divide and square root instructions are slow. They take many
cycles to complete, and they are not fully pipelined, so they block the ALU
while they are executing. Further, ARMv7 NEON does not provide vectorized
floating-point divide and square root instructions, so they have to be
implemented as a sequence of scalar VFP instructions.

All SIMD ISAs provide fast `f32x4` approximation instructions that compute 9-12
bits of 1/x or 1/sqrt(x) respectively. These instructions are fully pipelined
and typically as fast as a floating-point addition. They don't provide the
exact same approximation on different platforms, though.

**Poll**:

> Adopt `f32x4` 1/x and 1/sqrt(x) approximation instructions.

The `f64x2` versions of the approximation instructions are only available in
AVX-512 and ARMv8's A64 mode.

**Poll**:

> Adopt `f64x2` 1/x and 1/sqrt(x) approximation instructions.

It has also been proposed to remove the exact division and square root
instructions since they are slow:

**Poll**:

> Remove the `f32x4.div` and `f64x2.div` instructions.

**Poll**:

> Remove the `f32x4.sqrt` and `f64x2.sqrt` instructions.

Presumably, the answer to these questions should depend on whether the
approximation instructions are adopted.

#### Alternative to Swizzle / Shuffle

Tracking issue: [Alternative to Swizzle / Shuffle #8](https://github.com/WebAssembly/simd/issues/8).

The initial SIMD proposal contains fully general swizzle and shuffle
instructions that take a sequence of lane indexes as immediate operands. An
alternative proposal is to only define a subset of the possible swizzle and
shuffle operations that are known to map to fast instructions.

The `v8x16.shuffle` instruction is pivotal since its functionality subsumes all
the other swizzle and shuffle instructions. It can be implemented in terms of
`pshufb` or `vtbl` instructions that are quite fast, see the GitHub issue for
details.

**Poll**:

> Adopt the `v8x16.shuffle` instruction.

The `v8x16.shuffle` instruction is quite large with its 16 bytes of immediate
operands. Most of the time, shuffles with larger granularity suffice, and they
can be encoded with smaller immediate operands (one byte per lane).

**Poll**:

> Adopt the `{v16x8,v32x4,v64x2}.shuffle` instructions.

The `v*.swizzle(x)` instructions pick lanes from a single input vector instead
of two. Their functionality is subsumed by `v*.shuffle(x, x)` which requires a
`get_local`.

**Poll**:

> Adopt the `v*.swizzle` instructions.

SIMD ISAs have various shuffle instructions that are faster than the fully
general `pshufb` and `vtbl` instructions. An implementation is free to use
these instructions for the corresponding immediate operands on `v8x16.shuffle`.
The alternative proposal in the tracking GitHub issue is to define a set of
fixed shuffle instructions that are known to map to these fast instructions on
all ISAs.

**Poll**:

> Define a small set of primitive permutations that we know can be implemented
> efficiently.


## Meeting notes

Notes added here after the meeting.
