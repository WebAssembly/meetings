![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the March 18th video call of WebAssembly's SIMD Subgroup

-   **Dates**: 2022-03-18
-   **Times**:
    -   4pm-5pm UTC (9am-10am PDT)
-   **Location**: *link on calendar invite*

### Registration

You are a new attendee, please fill out this
[form](https://forms.gle/9eB2ZYaziPEcTJabA) to attend.

## Agenda items

1.  Opening, welcome and roll call
    1.  Opening of the meeting
    1.  Introduction of attendees
1.  Find volunteers for note taking
1.  Adoption of the agenda
1.  Proposals and discussions
    1.  Relaxed SIMD Progress updates (Zhi An Ng)
    1.  AOB
1.  Closure

## Meeting notes

### Attendees

- Zhi An Ng
- Yury Delendik
- Lars Hansen
- Andrew Brown
- Richard Winterton
- Thomas Lively
- Petr Penzin
- Johnnie Birch

### Relaxed SIMD progress updates (Zhi An)

Instructions are mostly complete, though Marat is going to add bfloat16 (?) operations.

Need to implement reference interpreter, Zhi An has provided initial implementation. Changes to test infrastructure has been made, though we don’t have full test coverage (not a phase 3 requirement). Spec text isn’t a requirement, though we made progress on that as well.

AB: feature detection, lots of comments

TL: need it to settle down, then need implementation, no plans for that yet, trying to hire people

AB: which part?

TL: toolchain side, depends on where the proposal ends up, engine may be trivial or complex, will want opinions from this group, any specific direction we should push on

LH: we should scope it to the use cases we have, not try to cover everything we possibly ever want. Some type of function level proposal seems to have some traction. Whether we want something local to the code section or some global ifdef.

TL: hope that doesn't block progress

PP: yea don't think it does. For feature detection, few people in CG were suggesting "is this fast"?

TL: it could be a separate structure, need a broad structure of how feature detection looks like, then follow up with "fast"

PP: outside of this group, few people want that, we might not care. Ben and Luke bring this up every time we meet.

AB: doesn't block us for phase 3, but blocks the long term progress of this thing. Don't think this goes the whole distance without feature detection

ZA: if we ship relaxed simd first, feature detection after, they are compatible, we can start using feature detection to detect relaxed simd

PP: thought the other way around, we should use it before we ship it before the standard

TL: if it were available, we would use it, it looks like path to standardize relaxed simd is shorter

PP: AR has some idea about profiles, are we considering that?

TL: had a presentation, but no follow-up proposal, or details, current state of feature detection does not include that.

PP: Can we collapse lists where the same element is repeated more than once?

AB: Can we add a comment or a description that `signed(j)` means that top bit is set? Otherwise people reading would have to make mental mapping for those.

ZA: We can try add this, I am used to working with the spec, so it feels like the rest.

PP: Maybe use `top_bit` instead of `signed`, though it isn’t obviously that one is better than the other.

LH: how much can we change this? last row is

ZA: first 3 rows are not as important, can add cases

PP: are nans canonical? if we canonicalize we might not get this in one instruction.

PP: a little concerned about notation, someone might look at it and not understand/follow it

ZA: any other questions?

PP: a little concerned about notation, but this is probably the best we can do now

ZA: yeah, the spec text can still be tweaked

### AOB

TL: PP was saying we didn't bring up the is fast feature, will be helpful for me to get more perspective there

RW: provided some comments on the is fast thing, could be useful, but we kinda want to use feature detection thing

TL: we want proper feature detection, will additional is fast feature useful?

LH: i think v8 scalarize?

TL: we don't do that anymore

PP: BT's interpreter will scalarize. It feels useful, even for differences between platforms, standard SIMD case. Can open door for things for scalarizing everything and is slow

RW: XNN does some initial testing before they kick things off, can move it to application side for them to determine. libyuv does that too, detect and fallback

PP: not done in official manner, they know what instructions gives different result

LH: comes back to what we said before, user define bits in feature vector

TL: wonder if we have multiple users doing more specific detection to use different code paths

PP: i expect someone else is already doing this

RW: what's the advantage in moving it down

TL: advantage of feature detection at the core, can do that at the application level and pull down different modules.

PP: the fast thing, on arm v.s. other platform

LH: nothing is fast, variable width bit shifts on intel, won't do so much better if you scalarize, different algorithm. is fast doesn't buy you that

TL: xnnpack detects arm/intel, use SIMD, but use different code patterns, more complicated than is_fast bit, tricky to specify

PP: tricky to specify, need a discussion about those use cases specifically, you would run app in profiler, change to suit platform, avoid shuffles on intel, not fast.

TL: user definable bits in the bit vector, big feature of conditional sections, not sure how we would build that into clang

PP: usually done for math libraries, rather than user code

TL: clang has support for that, multi versioning, user facing toolchain feature folks will use, compile down to feature detection proposal. don't know how custom bits in the feature vector will integrate with that at the source level, what do you put on the multi version attribute

PP: intrinsics, same as using cpuid, my first reaction for feature detection is that we need cpuid

RW: is fast is subjective, feature detection is objective, is fast is an app-ish type of thing.

PP: is fast, different cost, certain semantics

TL: no need for is fast, user defined bits to doing specific platform detection up front

PP: bring up that is fast is not just a binary, some kind of number

TL: the more detail we put into there, more difficult

ZA: you might need is fast for every instruction

PP: encoding cost
