![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the May 13th video call of WebAssembly's SIMD Subgroup

-   **Dates**: 2022-05-13
-   **Times**:
    -   4pm-5pm UTC (9am-10am PDT)
-   **Location**: *link on calendar invite*

### Registration

You are a new attendee, please fill out this
[form](https://forms.gle/9eB2ZYaziPEcTJabA) to attend.

## Agenda items

1.  Opening, welcome and roll call
    1.  Opening of the meeting
    1.  Introduction of attendees
1.  Find volunteers for note taking
1.  Adoption of the agenda
1.  Proposals and discussions
    1.  Phase 3 feedback for relaxed SIMD (Zhi An Ng)
    1.  Wasm SIMD integer extend from 8 to 32 bits (Petr Penzin)
    1.  Opcode update (Zhi An Ng)
1.  Closure

## Meeting notes

### Attendees

- Anton Kirilov
- Deepti Gandluri
- Evan Nemerson
- Petr Penzin
- Yury Delendik
- Zhi An Ng
- Richard Winterton
- Andrew Brown

### Phase 3 feedback for relaxed SIMD (Zhi An Ng)

https://github.com/WebAssembly/relaxed-simd/issues/71

Request to relax semantics for NaN and signed comparisons, by removing correlations between expected platform-specific semantics. Any result in instructions that can return multiple results should be valid. This can mean that results can change over time, which wouldn’t work for some operations, for example FMA. We want to propose fixing the semantics in the same execution environment, but without correlation between different instructions.

PP: how to formalize this?

ZN: we will share this with Adnreas and Conrad

PP: what was the feedback about detecting platforms?

ZN: they raised it as a concern, and not a hard no. If we allow users to detect the platform we should have a good reason why we want to allow that. We’re willing to expose the platform dependent bits to the user

DG: there wasn’t too much concern, usually concerns come from browsers, when we do privacy reviews, etc, It was more of a discussion rather than concern.

PP: We could use feature detect to formally detect the semantics - instead of actual computational detection.

DG: we want to make sure we detect high level features, CG can check if it is too high level or granular. Exposing too low level details as part of feature detection would encounter pushback

PP: still possible to do similar detection, if we don't have explicit API, we encourage people to do it less

DG: as we are writing the standard, we decide what tools we give developers. That's parallel to CG conversation, we don't want people to rely on those type of semantics. If hardware changes, or we support newer changes, whatever we have, it's at a higher level of granularity.

### Wasm SIMD integer extend from 8 to 32 bits (Petr Penzin)

https://gist.github.com/penzn/e3f867b340f4fb650840e2ff8617c360

PP: we have extend 8 -> 16, and 16 -> 32. x86 has 8 -> 32. For image processing algorithm, 8 bits, computation on color values, result may no fit in 16 bits, use 32 bit int. Will have some benefit. We tried to evaluate this

DG: have you filed a toolchain bug? This could be an optimization issue in autovectorizer, for example.

PP: at some O level LLVM doesn't turn on simd128, have to turn on optimizer and simd support. Could be vectorizer, but more of a codegen problem, can detect extend mask in the backend, then check correct sequence and instruction.

DG: if we want a 8->32 extend, is this something you want to spin up a proposal for? you'll still need a lot of performance data to justify. Figuring out if toolchain can optimize it will be helpful. If you take it to CG as design issue, that's likely the first question.

PP: if i go to design today, it will be heavy, we don't have an example that does this yet.

AK: we were talking about codegen x86, can see this benefiting ARM, especially for SVE extension, there are loads with extension, can be generated with single instruction. Runtime can pattern-match. The shuffles and patterns there make it quite difficult.

PP: What you see on the screen is not good, last night I was trying to find what ARM does, couldn’t find it exactly

AK: doable with SVE, not exactly the same semantics, you have extensions of overlapping elements, what you're looking at is 8 bit extend element 0 1 2 3 4 to 32. With SVE you extend 0, 4, 8,the same elements which have to be in the same 32-bit granule. Has an extension from 8->32 but doesn't match the semantics here. There are loads with extensions that match your semantics.

PP: Makes sense, will still be faster probably

AK: this particular example, there is a dot product instruction that involves signed or zero extension and then addition, could be useful for this particular example.

PP: We have the dot product instruction

DG: how widely is SVE available?

AK: in SOC released this year, ARMv9, mediatek, one plus phone.

PP: What’s the new dot product instructions?

AK: Available in both

AK: good to be forward looking, SVE is a mandatory part of ARMv9, future SOC will be ARMv9 based.

### Opcode update (Zhi An Ng)

ZA: Browsers and toolchains that have to update the opcodes, previously we were using the holes in the SIMD opcode space, decided to move it to a more consistent opcode space. In the overview there’s a binary format section, the opcodes there should be up to date. Both toolchains and engines should use new opcodes.

DG: V8 using new opcodes since 1 week ago, toolchain might be mismatched, need to sync with Emscripten. File an issue to track browsers and toolchains. How about Firefox?

YD: Firefox updated, dot product also updated, PR not merged.

ZA: I’ll file an issue for opcode coordination

Browsers will also probably pull in spec tests shortly
