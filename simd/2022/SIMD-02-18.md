![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the Feb 18th video call of WebAssembly's SIMD Subgroup

-   **Dates**: 2022-02-18
-   **Times**:
    -   4pm-5pm UTC (9am-10am PDT)
-   **Location**: *link on calendar invite*

### Registration

You are a new attendee, please fill out this
[form](https://forms.gle/9eB2ZYaziPEcTJabA) to attend.

## Agenda items

1.  Opening, welcome and roll call
    1.  Opening of the meeting
    1.  Introduction of attendees
1.  Find volunteers for note taking
1.  Adoption of the agenda
1.  Proposals and discussions
    1.  Preparation for phase 3
    1.  Open issues not yet merged in the spec
    1.  AOB
1.  Closure

## Meeting notes

### Attendees

-   Andrew Brown
-   Deepti Gandluri
-   Evan Nemerson
-   Johnnie Birch
-   Lars Hansen
-   Marat Dukhan
-   Petr Penzin
-   Richard Winterton
-   Thomas Lively
-   Yury Delendik
-   Zhi An Ng

### Preparation for phase 3 (Zhi An Ng)

ZA: Resolution of fpenv discussion: there are open questions in the current
spec, some inconsistency is allowed, ex.: fused multiply and non-fused add, etc.
Before phase 3 we need to finalize instructions, add tests, and agree on
instruction prefixes. Additionally we might need to work on feature detection,
since we are adding more possible features.

DG: bring up feature detection to CG again, try to phase 2, see what open
issues, can prototype, need to find the right people to do it.

AB: is fpenv a blocking issue?

MD: fp sub defined via fma with negated operand. not sure if min/max need to be
consistent, cpu may prefer to lower min and max to vectors using a single
compare, which would be asymmetric.

AB: what was the state of fpenv discussion?

ZA: there is no explicit fpenv parameter in the spec anymore, instead we assume
that there will be consistency in operations

AB: fpenv on x86 can be changed by MSR

LH: no, no runtime presence of this at all

MD: you can disable FMA instructions, will be different fpenv

LH: that comes into play when we cache machine code, capture the fp status
register and make sure it doesn't change we we reload

AB: seems fine, likely no one is messing around with it, if they did, with
different MSR

LH: only migrate code between processes

PP: majority of stuff that happens there is rounding mode, etc, can't turn off
FMA

DG: from v8's perspective, don't expect to provide user visible flags for
different semantics. Problem with caching, one way to get around it is to
compile the compiler everytime. Seems like the folks using relaxed simd will be
aware of this.

LH: i care less about users, then bug triage people who get very obscure crashes
from this

PP: relaxed simd generally feels like this, general philosophy, can't depend on
this to do the same thing

MD: would be helpful for developers for them to test different fpenv from the
native one, could be interpreter, no need to be performant interpretation.

LH: can imagine a config flag in the browser, that compiles relaxed this way or
that way

MD: doesn't have to be in browser, like a standalone engine

AB: spec interp maybe

MD: yea

ZA: seems like a quality of life improvement, not super blocking

AB: agree with DG, occupational hazard, relaxed is a big warning sign that we
can have differences on different arch

PP: in general, people dev on different platform than it runs on, people will
have difficulty using it, don't see any better way to do it

DG: we had this entire deterministic push, the objective of this is to relax
this, we can do some things here, don't know if we can get rid of all the
weirdness. E.g. for testing, relaxed simd fuzzers can flag some
non-deterministic, so don't crash. If users will migrate this, it will be
different. Relaxed simd is a different thing that developers have to work
around.

EN: will be willing to add different flags to SIMDe to help people test
different fpenvs

### Open issues not yet merged in the spec

Relaxed rounding Q format. There are discrepancies between Arm and x86.

MD: guarantee results only if highest bit of second input is 0, 8 bit by 7 bit
dot product, enough to be the same, neural networks, neurons can be 7-bit
unsigned (activations always positive), weights as 8 bit signed, get 2x speed up
with special instructions. unlocks native dot product, multiples quad in one
element with another, produces 32-bit output.

YD: judging by instruction name, what instructions are you proposing

MD: proposed 4 instructions, unsigned and signed variants, accumulate to 16 bits
(2 elements)

YD: is it really relaxed? or can it be guaranteed.

MD: if want to be portable, have to be relaxed

YD: we are limiting 7 bits

AB: users can put whatever they want

MD: doesn't mask the high bits, result only guaranteed for 7 bits

LH: we need to ask kenneth if this can be used in their kernels, not sure if
they depend on it

YD: looks at it, really depends on 8 bits, want to use all precision. he detects
8 bits

PP: will we be able to enforce 7 bits?

MD: not enforced,only guaranteed if you use 7 bits

PP: you can enforce it in the engine

MD: relaxed swizzle instruction, guarantees only inputs are in range. same here,
only when input is in range

PP: trying to follow up on what Yury said, there is no way to make this strict
(non-relaxed)

AB: can zero top bits

PP: it ignores extra information

LH: shift left shift right

AB: this is relaxed simd, user can do that too

MD: on arm, thats one instruction to zero high bit, on x86 depends if mask is in
memory, user guarantee that it is in range

AB: XNNPACK can use this instruction?

MD: doesnâ€™t have 7 bit elements, but can adapt to it

ZA: can we get Kenneth to look at this too?

YD: he is targeting Intel architecture

DG: seems like we have a small number of outstanding instructions, any big
instructions others want that have not added issues for?

### AOB

JB: what's the intent with relaxed simd if there is some instruction that was
missed, multiple versions

DG: can spin up proposal and move it along. I imagine this as some subset of
instructions solving a particular use case, some logical subset of instructions.
There is a burden of doing the work to make it a standard. If we think of
something, consider it for this proposal.

JB: wondering if there was some additional instructions, will there be a more
stringent process

DB: not particularly stringent, there is overhead in spinning up a proposal, a
new branch

MD: a class of instructions we talked about, approximate reciprocal, and other
approximate instructions. We can even have all libm functions as approximate
instructions. They are non deterministic differently from relaxed-simd,
relaxed-simd we can enumerate the differences. These instructions, on way to
enumerate, it will be in the millions of different variations. Leave it out,
potentially next proposal. Don't see that much speed up from reciprocal
instructions on recent CPUs. Native division is sufficiently fast, as long as
algorithm is not doing division all the time. E.g. in division in sigmoid, not
very conclusive wins.

ZA: probably a good idea to leave this to a different proposal

MD: maybe define instructions not in antive, approximate exponential, on native
will be multiple hardware

PP: how to define output?

MD: define accuracy of output, will have millions

DG: no objections for approximate instructions to different instructions, was an
old issue on simd proposal

MD: one more in mind, bfloat 16 dot product instruction. it can be polyfilled by
extending bfloat to fp32, then using qfma, need to check if results are really
different across different cpus, some newer CPUs have native instructions for
bfloat16, not sure if they differ on x86/arm and what we can polyfill.

DG: process note, any objections to doing agendas the way we do regular CG
agendas, in meetings repo

ZA: can still have the issues, will copy paste agenda items to meetings repo
agenda

PP: other subgroups doing that

DG: GC moving to the main cg process now

TL: yes, have moved

DG: stack switching, more adhoc

LH: echo Andreas comments, name should reflect it

DG: relaxed might be too long, maybe nd (non-det)

LH: instruction names are already very long

MD: not as big deal, care more about intrinsics

ZA: intrinsics match closely instruction name, for discoverability

AB: in favor of relaxed prefix, links intrinsics, proposal, and instruction
names

MD: summarize up the plan forward, on board with stage 3, rename instructions, q
format mul, dot product

DG: for open issues, engine will prototype come back with feedback, phase 3
needs test suite, text format names and opcode not as important, can bike shed,
implementations agree, design consensus

ZA: feature-detection, will we be blocked on that

DG: move along together

ZA: action item for everyone to look at outstanding issues not in overview (will
tag those issues) and comment or thumbs up

AB: for spec tests, are we adding to wast to detect range of results?

MD: oneof result

DG: file issue on this, see what needs to change in test infra
