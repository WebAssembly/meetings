![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the May 14th video call of WebAssembly's SIMD Subgroup

- **Dates**: 2021-05-14
- **Times**:
    - 4pm-5pm UTC (9am-10am PDT)
- **Location**: *link on calendar invite*

### Registration

You are a new attendee, please fill out this [form](https://forms.gle/9eB2ZYaziPEcTJabA) to attend.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking
1. Adoption of the agenda
1. Proposals and discussions
    1. SimpleV (Jacob Lifshay)
    1. Masks (Florian Lemaitre)
    1. SVE implementation in SIMDe (Evan Nemerson)
1. Closure

## Meeting notes

### Attendees

- Andrew Brown
- Arun Purshan
- Deepti Gandluri
- Evan Nemerson
- Florian Lemaitre
- Jacob Abraham
- Jacob Lifshay
- Jan Wassenberg
- Marat Dukhan
- Petr Penzin
- Rich Winterton
- Zhi An Ng

### SimpleV (Jacob Lifshay)

JL: SimpleV is the instruction set designed for LibreSOC, vectors up to length 64 (number of elements). Like RISC-V ‘V’ extension, variable vector length register, CPU designed such that all implementations always support length 64 vector, can execute one at a time or execute groups of elements.

It supports fixed-length vectors on all archs, you can set the VL register to whatever value you like. 

EN: any way to use this today? A compiler or library to emulate it?

JL: software emulator, written in python, you can find it at libre-soc.org.

EN: will be interested to adding support for SIMDe to experiment a bit

JL: don’t think we have assembler/compiler for that, people working on GCC

EN: lmk when you do, i’ll be interested

PP: how do you run this now? Fpga impl?

JL: working on FPGA implementation, working on asic for it, can also find source code for that at libresoc

PP: different ways of executing it, sometimes you have vector processing, what kind of configurations do you support.

JL: currently, the instruction decoder part will take the SimpleV instruction, spit out every single element, to the instruction scheduler will group together and send it to a SIMD execution unit that executes it at once.

PP: interesting

EM: you could have 22-bit vectors, by passing that in length registers

JL: 22 bytes

EM: no real need to worry about predicates, you use that registers, no predicates?

JL: yes you have predicates, if you want first 3 lanes but not last 4

EM: mixing on and off, dedicated predicate type? Or a second vector and you AND them

JL: dedicated predicate type, ISA is based off on open power, vector of conditional registers, also support just bits in a 64-bit integers. This is why we are limited to length 64.

PP: worked with open power a bit, vector of conditions are hard to manage

JL: not based on open power SIMD support, independent thing. It is based on scalar instruction, prefix, runs in a loop

PP: cool. What kind of performance do you see / expect to see from this

JL: for initial implementation, we set it up with 128 bit wide SIMD execution units, we’re using an older process to keep costs down, we’ll probably end up limiting to 800 mhz. 50 gflops. 4-core processor.

PP: how will this compare to something else, say when you take ARM or Atom.

JL: we have been comparing to Raspberry Pi GPU. approximately equivalent

FL: q about vector length, what is the goal of the vector length register, is it for loop prologues, or just to set up preferred length of computation

JL: vector length register tells the processor that you don’t have to execute all 64 lanes, just 5 or whatever you set it to. You won’t have to do 16 clock cycles when you only have to do 2, if the processor can only do 4 lanes at a time

FL: what happens when you reduce VL to data that is out of bounds in registers

JL: we have instruction for setting VL, kind of like simpleV one, it is just an immediate to instruction, compiler will set it based on number of registers allocated for the instruction

FL: not clear

JL: instruction has an immediate that says maximum length allocated, another arg that is an int arg, will use the smaller one as the vector length, the programmer can have a loop that goes back to do the next X elements. Language level help for loop strip mining. Better than traditional SIMD instructions, we don’t have huge gigantic complicated code for cleaning up the extra ends.

FL: assuming we want to do a sum of an array, what you would do with predicate and mask is, each iteration, the full length, last iteration you mask the load of the last elements, with set length like in RISC-V V, last element of accumulator mandated to stay, thus when you reduce the elements of the register, you reduce all the elements, and not only the remaining ones. Is this the same in SimpleV?

JL: yes, if you have VL set to less than max length, it won’t modified any of the element past the vector length. Perhaps unlike RISC-V V, not sure if they require elements to be unmodified. If you run the configure vector instruction, it throws away all the stuff.

FL: RISC-V elements after vec length mandated to remain the same value

JL: good, then it is the same

JW: that is configurable, that is a mode to choose between undisturbed and don’t-care

PP: when you came to say that you are working on open source SOC, it was unclear what it means, looking forward to see progress.

JL (chat): iirc here's the SimpleV link https://libre-soc.org/openpower/sv/overview/

### Masks (Florian Lemaitre)

[Slides](presentations/2021-05-14-lemaitre-rfc-masks-challenges-for-wasm-flexible-vectors.pdf)

PP: we have different archs that we want to support that have masks, not the same general mask support, not the same interaction. It won’t be easy to reconcile. When you compare the mask representation it is different. There are also different operations, difference between AVX and SVE.

FL: most of the operations you could do the operation on another register, then do a select, this is the naive fallback, if there is a missing operation, except for stores.

PP: don’t know how easy it is to represent that in tools (LLVM), compilers don’t expect that the mask operation returns result and masks

FL: don’t have feedback on this, don’t know well enough LLVM

PP: LLVM is less of a problem, it’s more how complicated this will be. If we take some common code that we want to support using this, are we going to have explosion of the return values, maybe you need a different variant of instruction that does not return the mask.

FL: if you go this way, you will have many opcodes and this might not be something we want. That’s why I was thinking about a mask stack, where mask operations just read the mask stack, but don’t touch it. And only operations that write masks actually pop this stack.

PP: This is kind of a global state. We have in the relaxed simd proposal, an environment, we can set this similarly. If you have to constantly update something on the stack, it depends on the situation, what the engine can see and optimize out.

FL: don’t know how to handle, if the Wasm engine is able to detect that the mask is full with constant folding, and with monomorphization, basically you will probably not need to add separate instructions for with mask and without. Problem is that you will need to have a different instruction for zeroing operations and merging operations. Because those two are useful. But maybe this can be encoded in the type of mask, not sure.

PP: we should try to solve this, not necessarily going to happen right away. As we push forward this design, we should try to make sure we don’t cut of masks, need to keep the door open for them to be added.

FL: anyway, masks are basically mandatory because 128-bit SIMD we don’t need mask, there is the implicit mask being a full register. In SVE and AVX-512 and RISC-V V, when you compare, e.g. if you get a mask, you don’t get a vector. If you say comparison returns vector, then you need a smart engine that doesn’t do the double conversion from mask to register and other way.

PP: anyone else has questions? AP has an hand up.

AP: forgot to turn it off.

JL: might be helpful to see what Rust compiler is working on for the design of their portable SIMD library. They tried to have a default mask be an opaque mask, there is a separate mask type for each width of element, layout is not specified to be any format.

FL: yea, think that is the way forward

PP: basically have to have a portable mask type, the challenge is where and how and at what level to translate to hardware. Whatever we can invent in terms of portable type and how it maps to hardware instruction.

### SVE implementation in SIMDe (Evan Nemerson)

EM: FL covered a bunch of problems. I can cover some practical stuff. Just started implementation of SVE on top of AVX-512, NEON, altivec, Wasm, etc. By far, the predicates are the most painful. That is the only area where we have had trouble. What we do now is, SVE has that svbool_t that represents everything, that is in SIMDe an opaque type, which has an mmask64 variable, everything is at the c value, intel k registers on AVX-512. We store separate what type it is, that difference in how stuff is represented in memory is the major problem. SVE api section 3.5, talks about how the least significant bit in every lane controls everything, the holes don’t affect it. There is no good way to get that out for the API. Overall if you use the API as it is intended, you don’t see problems. Clang is good at eliding all the code to check, everytime we run an operation, we want to pull the mmask variable out of opaque type, and check it matches. Good way in AVX-512 to convert mmask8 to mmask16, but no way to go backwards, clang elides all that. Can share an example on compiler explorer. Fixed length loop using SVE api, compiles to exactly what you would do if you would write AVX-512 natively. GCC doesn’t look as well, haven't looked at MSVC, not had good experience with MSVC optimizations. Most complicated is predicates, everything fell into place neatly after solving that. I like the idea of exposing predicate types in flexible-vectors proposal. Came to the same conclusion as FL, the way to go to iron out differences in the arch is to have different types for different element types (8-bit lanes, 16-bit lanes, etc.) If you did that, everything kind of falls into place, and works out neatly, from my experience on SIMDe. AVX-512 on SVE, intel has a richer set of permutation operations for 512 bits and 256 bits, SVE’s permutation and selection is quite limited. There is an issue out there to add zip and unzip, don’t think SVE supports pair-wise operations, pair-wise addition. With zip and unzip it will be trivial to implement those. There is TBL, like swizzle in Wasm SIMD, that operates on the entire vector. You don’t know at compile time what vector length, you may have 512 or 256. It is any multiple of 128 bits, not just power of 2. You can have 384 bit vectors. A64 FX, only hardware with SVE support, it supports 128, 256, 512, doesn’t support 384. You can request specific lengths if the compiler supports, but not guaranteed. You cannot count of any specific length being supported. Overall, permutations are big, biggest ones are predicates.

JL: when i looked at SVE spec a while ago, they guarantee all power of 2, not the other ones.

EM: will take your word on that.

PP: it’s not that one is worse than other for permutations, but just different philosophy. We had these sort of issues on Wasm SIMD spec, some operations become so expensive, you add more and more instructions and become more complicated. Once we get number of opcodes under control I’ll go back and look at permutations. This meeting ends up being about masks for most part

EM: expect many more meetings will be about masks.

PP: exception of RISC-V, masks are most important, that’s how you turn lanes on
