![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the June 11th video call of WebAssembly's SIMD Subgroup

- **Dates**: 2021-06-11
- **Times**:
    - 4pm-5pm UTC (9am-10am PDT)
- **Location**: *link on calendar invite*

### Registration

You are a new attendee, please fill out this [form](https://forms.gle/9eB2ZYaziPEcTJabA) to attend.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking
1. Adoption of the agenda
1. Proposals and discussions
    1. Performance expectations of relaxed-simd instructions (Zhi An Ng)
    1. Eliding AND before lane shift (Petr Penzin)
    1. Update on flexible-vector opcodes (Petr Penzin)
    1. Opcodes for relaxed-simd (Lars Hansen)
    1. Documentation on SIMD instructions implementation (Evan Nemerson)
1. Closure

## Meeting notes

### Attendees

- Andrew Brown
- Arun Purushan
- Evan Nemerson
- Johnnie Birch
- Lars Hansen
- Petr Penzin
- Thomas Lively
- Yury Delendik
- Zhi An Ng

### Performance expectations of relaxed-simd instructions (Zhi An Ng)

ZN: As we were working on SIMD ISA we were setting expectations for adding instructions (performance, use cases, etc). We would like to have criteria for relaxed-simd proposal as well.

LH: would think that at a minimum we should show that relaxed simd instructions perform better than similar sequence of simd instructions, every relaxed instruction should perform better than the counterpart or the multiple instructions required, would be nice to see it in real applications

JB: main motivation is performance, not sure if there is any other reason? Benefit one platform, or all platform?

LH: we have performance traps on some platforms for some instructions, will be okay if it benefited only those platforms. If a platform already has good perf, it can’t be better

AP: agree, and add to that, consistent performance can use SIMD 128

ZN: if it is a single instruction lowering we probably don’t have to debate to much for adding it

LH: for example dot product has 3-instruction lowering on x86 until we reach AVX-512, the alternative emulation is horrible

ZN: so we have to compare emulation v.s. the lowering, see how bad the difference in performance is, and look case by case

PP: if we know simd has poor lowering, we don’t have to see symmetrical performance gains on all arch, since we are fixing it

### Eliding AND before lane shift (Petr Penzin)

PP: hardware discovery on relaxed-simd, Marat points out that XNNPACK detects that using abs of neg infinity. Shuffle operations have potential platform specific behavior, you can know which platform you’re on, and you can use different shuffles, do different things with inputs, is that something we support?

LH: this comes down to what SIMD programmers think serves their case, for feature detection proposal we talk about lowering to constant so we can compile away code completely. Don’t know if dispatching on specific hardware is what we want to do. Doesn’t sound like a problem really

PP: don’t feel it is a problem too, but curious if this is what we would rely on, or would we invent a different mechanism for dealing with platform specific behaviors

TL: personal opinion is not want to expose platform differences explicitly, even a feature detection bit for x86 or arm. Also have a hard time seeing that fly in the wider CG. For similar reasons, people will be skeptical about relaxed-simd. Would expect not doing anything to make platform detection easier. Would not recommend to users to detect it.

LH: at the moment, the relaxed instruction have a lowering on every platform, they can always use the instruction and expect to work

PP: has slightly different versions for the kernel, for x86 and arm, you can expect more of this for relaxed-simd, since instructions behavior different

EN: also talk on issue tracker for fingerprinting, with TL, leave it alone, don’t make it explicit feature detection API, always ability to do it, and do timing attacks, not worth fretting too much so people can’t detect their platform, you can’t control what people are going to do

ZN: undefined behavior, can’t prevent users from exploiting that, also we can use JS to detect platform differences 

PP: a lot of other fingerprinting surfaces

ZN: we still have to consider fingerprint, so far the instructions have been Intel v.s. ARM

PP: what about other virtual instruction sets?

ZN: fma with does fused, hardware supported is fast, otherwise using algorithm, muladd which uses hardware fma if available

PP: emscripten emits AND if you have lane shift

EN: shift left count and 15, question for TL too, not a compiler person, have seen compilers do much more insane stuff then eliding an AND, this isn’t calling an intrinsic, wasm i16x8 and is actually just implemented as vector extension left shift in LLVM, when you write that code, not sure at what point it converts to Wasm intrinsics

TL: it’s totally in scope for LLVM backend to remove the mask, we do similar things for other instructions, this is just a classic instruction selector optimization we should be doing

PP: do we carry this type of info, the shift carry and AND?

TL: not in the LLVM IR layer, where you can’t have shifts that are larger, forget about semantics, probably poison, in backend, when doing instruction selector, and generating Wasm instruction, and can make assumptions about Wasm instruction, will be doing this in the backend, Wasm-specific instruction selection. Was working on SIMD for a bit, recently doing other stuff, won’t get back on SIMD for a couple more weeks, because shift from Chrome 90 to 91, emitting recently changed instructions by default on LLVM, causing issues for users who want to continue to support end users with older Chrome. Until that settles down, will continue working on non-SIMD stuff. Intend to come back and burn down bugs in LLVM bug tracker.

PP: I can look up version we target, any SIMD tags we target?

TL: not a lot of simd bugs in LLVM bug tracker, best to look at Wasm bug and scan down the list, see which ones have to do with SIMD

EN: some bugs to file from optimizations coming from wav

TL: no rush

EN: will do them within next few weeks

### Update on flexible-vector opcodes (Petr Penzin)

PP: wanted to update on flexible vectors. When the whole thing started, we had a discussion about this. The way we presented flexible vectors, it would have lane tags, i8, i16, etc. But we try to add opcodes, it takes up a lot of opcodes, if you take every operation, make a flavor that is valid, if you try to check any bit is true for example. That bloats the space, we cannot be so generous with opcodes. We have to go back with untyped lanes, or polymorphic input types, no precedence for polymorphic operations.

AB: you’re coming up with more than 255, with just the instructions we want in the first pass

LH: prefix byte + arbitrary large leb

PP: yea, we take a whole byte anyway, that’s another option, we just go with it anyways.

LH: it’s not like the instructions will dominate programs

PP: yea, good point

AB: not an option to have 2 prefix opcodes?

PP: can make them as long as you want

AB: if you have fb and fc as prefix opcode.

PP: so far everyone try to use only one, you can use 2 bytes of opcodes

TL: opcodes have single prefix byte and the rest is leb encoded, probably we won’t want to do 2 prefix bytes, we already have an extensible system that everyone has decided on

PP: the way that you write those you can see the first byte

TL: using the leb you can draw out your opcode map

ZN: leb can have redundant bytes, so need to be careful

PP: if overall this is ok, will continue

AB: doesn’t sound like a big issue, opcodes will be longer

PP: sounds like a good direction, makes me happy

### Opcodes for relaxed-simd (Lars Hansen)

LH: since we are talking about encodings, what about relaxed-opcodes

LH: whether people were opposed to using the SIMD opcode prefix

AB: don’t mind that idea? Haven’t followed the feature detection proposal, quick updates on it?

TL: there are 2, conditional sections, considered dead and feature detection proposal is very basic. It is a decoding hack that has a block of instructions that may or may not validate. Basically an i32.const that depends on what features are available. Simple proposal, when we need it for these use cases, it won’t be too long to prototype and push it in CG.

PP: there’s a feature detection repo?

TL: yea feature-detection

ZN: so share the same prefix byte, but different opcode to existing SIMD proposal

JB: once relaxed-simd goes through, would it be considered optional or spec compliant need to implement

TL: i would like to get feature-detection in before relaxed SIMD. there is a profile suggested by Andreas Rossberg, feature-detection is sliced by what instructions are supported, profiles are split out by use cases, maybe block chain profile without float ops. The story around optional features or profiles, would like to make progress on that. Possible that relaxed-simd proceeds faster

LH: with feature-detection in place, it will be easy to add instructions, but the types make it hard

TL: feature-detection makes it easy to have optional instructions, as long as you don’t add new types. Decoding of v128 type is not optional, but what they can do is to lower any function that has a v128 in its signature can be an unreachable function. Something like that. Main idea is that the type remains non-optional, but you can do something trivial.

ZN: trivial for SIMD to support relaxed-simd

LH: true currently, not true for instructions like the dot product

TL: decoding is a different level of abstraction

ZN: we can pick an opcode for prototyping first, and change depending on progress of feature-detection

### Documentation on SIMD instructions implementation (Evan Nemerson)

EN: documentation, a lot of it in issue tracker that talks about how to implement instructions, maybe a wiki or separate resource

AB: quick comment, this came up in the past, we couldn’t decide what official place to put this information, we had some data, Arseny had good data somewhere on a GitHub repo

PP: put it in the simd repo

AB: Deepti mentioned the repo will be gone

PP: if CG decides to delete it and move it around. Wasm doesn’t have a developer manual. There is no precedent of documenting that yet

EN: more focused on using that information while people are working on the relaxed simd proposal, think that could be valuable for people after it is shipped, as V8 is updated, as RISC-V support is added. Valuable for people trying to write code to target simd proposals.

PP: this should be a developer manual

EN: i will be generating this data soon, should this be markdown, some static site

AB: what’s this data again?

EN: what instruction will be generated for i32x4 add, what instructions on ARM, x86

AB: what engines?

EN: a lot of commonalities, general guide, even if we add all v8 data, we can come up with new stuff. At least give people an idea, what is the best implementation we know of, it can evolve over time.

TL: bar is pretty low to add more information to the Emscripten site, know it is not the most neutral vendor-dependent option, separate website is a lot more overhead than putting on Emscripten

EN: can put data in separate repository, emsripten can pull that data in, can be somewhere it can be shared easily. So any project can pull that data in and use that in their documentation, as long as it exists. My plan is to look through issue tracker, and Zhi will help looking through V8.

LH: what’s your plan for instructions like shuffle?

EN: haven’t thought about that too much

PP: will need a lot of documentation for this

EN: can say for shuffles what builtin_shufflevector will generate on your platform, for everything shuffle like there is swizzle, it is Tbl in ARM. Shuffles are definitely and outlier there

PP: i can help with the shuffles side, it’s definitely going to be big, but there is a system to it, different shuffles we recognize, depending on the mask we do different things.

EN: the difficulty for shuffles should not prevent us from doing for other instructions

AB: any reason we cannot have a new repo called simd-developer-manual that we stuff this data in? If simd goes away it still lives in some official place?

EN: just time? I can create a new repo and transfer it easily.

PP: if you have time to create it, make sure you have permissions to do it

AB: easily to transfer

EN: yea public domain

PP: go through CG, 

ZN: appendix?

EN: instead of just simple markdown, have some structured data

ZN: write xml/json, then generate markdown

PP: not markdown right?

ZN: yea restructured text

ZN: check out zeux/wasm-simd

EN: yea we can hook it up with compiler explorer, and can have llvm-mca to get cycle times

ZN: we have some discussion on this, but difficult to run v8, get disassembly and codegen and map it back to SIMD instructions

EN: with SIMDe we don’t have to do that, will be easier
