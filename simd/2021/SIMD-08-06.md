![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the August 6th video call of WebAssembly's SIMD Subgroup

- **Dates**: 2021-08-06
- **Times**:
    - 4pm-5pm UTC (9am-10am PDT)
- **Location**: *link on calendar invite*

### Registration

You are a new attendee, please fill out this [form](https://forms.gle/9eB2ZYaziPEcTJabA) to attend.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking
1. Adoption of the agenda
1. Proposals and discussions
    1. WASPR (Evan Nemerson)
    1. AES
    1. SIMD ship status in browsers
    1. SIMD instructions with multiple return values
1. Closure

## Meeting notes

### Attendees

- Andrew Brown
- Deepti Gandluri
- Evan Nemerson
- Jan Wassenberg
- Johnnie Birch
- Lars Hansen
- Marat Dukhan
- Sergey Rubanov
- Yury Delendik
- Zhi An Ng

### Waspr (Evan Nemerson)

https://nemequ.github.io/waspr/instructions

EN: From SIMDe, using LLVM MCA, parsed out

ZN: This linked anywhere? Emscripten or anywhere? We should put a note in emscripten - there is a table there that describes lowerings, but this could be useful too. Would you like to add it to the docs?

EN: Can figure out where it is

ZN: Can send you a pointer

AB: I can send you data as well

EN: If you send it in this format, I can integrate. Willing to figure it out

ZN: If you need a way to figure out how to get data from V8, file an issue and cc me, and I can help you as well

EN: Would like it to be automated

AB: It’s linux specific, if you’re fine with that then..

EN: I use linux.. Would like github actions to build the lowerings, some sort of issue during cross-compilation, would like to integrate that. The platform we generate the data on does not matter.


JW: Double to int conversions are very branchy.

EN: Will take a look at it, the big orange box has a warning about inaccurate instructions, there is a link that should take you to the implementation. I did the portable ones to start with, going on to add optimizations, but help is appreciated. Will get around to it eventually

JW: Branches come from scalar code, can share an implementation that might help.

MD: Lowering for ext-mul-high looks off on ARM, maybe LLVM bug?

EN: Have not added optimized implementations for this. These are the same issue that I added bugs on the issue tracker for the Wasm backend. (Check with Thomas)
This is especially the case if you disable the native implementations. IT would be great to improve the compiler to the point where it generates the same data.

MD: Tried in compiler explorer with the latet LLVM, seems to generate the right code

EN: Generated on clang11, but I’ll paste a link, there is a way - amalgamated headers for each architecture, easy to play with compiler architecture.

MD: Went back to clang11, and still generates the right code looks like a simde bug `extmul` instruction

EN: it’s the 8 -> 16 bit one?

MD: all ext except 32 -> 64.

MD: Using slightly different lowerings in V8, lower + shifts instead of two shifts.

ZN: It’ll be easy to do this when Andrew shares automated..

MD: Is there a way to see this for Firefox?

AB: More familiar with V8, but not sure how to do this in spidermonkey

LH: There’s a way to dump it from the engine in the log, or with JS - use it to verify disassembly.

ZN: If you want to check for the jit code, there’s an open bug for it, so reach out if you run into issues

AB: tried it in the past, and it looked ok. Is there anyway to get JitDebugInfo out from SpiderMonkey?

LH: print to stdout is the way, don’t mind adding stuff to the shell

AB: send me info on how to print to stdout?

EN: Just posted the link to the tool used for generating the code, we could coordinate on the issue tracker today.https://github.com/nemequ/wasm-simd-data

### AES

ZN: Nothing more on the agenda, should we discuss AES?

(ZN describes PR, summarizes replies)

JW: flexible vectors could be an option?


ZN: At this point it depends on whether they want to tie the advancement to flexible vectors, this independent of flexible vectors would be useful. Splitting from flexible vectors makes sense, and then PP can decide to include for the flexible vectors.

JW: useful op, whatever is quickest to standardize is best

MD: there are some users of Wasm who strongly prefer to have no non-det in it, it’s likely these uses will never ship relaxed simd proposal. Or ship it in a constrained way. So preferable to not bunder deterministic instructions into the same proposal.

AB: a bit of friction in creating a proposal and taking it to the CG, they brought it here because it was easier

MD: there is web crypto API, in JS, not Wasm. Designed with a single purpose of exposing crypto. Think there is not much benefit from exposing this in Wasm.

JW: I have seen use cases that would benefit from this - like a permutation or a hash, not a cipher.

LH: one thing to bring up to CG is to have a process to add simple instruction, not just SIMD, like byteswap. Should be simple and minimal friction, straightforward and has utility. Can there be a streamlined process?

DG: we’ve been trying to do more nominal changes, esp when it comes to Web API, or small spec changes, maybe we can do something of this sort for opcodes as well. I can add it to next CG agenda to discuss this.

ZN: Up to the person who brings it up to see how they’re willing to push forward with it.

### SIMD ship status in browsers

AB: Intel discussion about Safari support for Wasm SIMD, what their status is. What they feel about relaxed-simd and AES.

DG: Safari’s stance is usually they don’t comment on implementation until they ship. As part of Chromium shipping process, we have to collect Intents from other browsers. Safari is positive towards SIMD, doesn’t mean they will implement it soon. Relaxed-simd will be the same thing, if we find a good enough use case, don’t see them opposing it, but don’t see them rushing to implement.

AB: Wasm SIMD is in stage 5, so that means it’s done. Or they going to have a non-compliant browser for some time.

DG: not new for them, they dont have some proposals like bulk-memory. Different applications feature detect and ship different versions to different browsers.

AB: is there a place that tracks the status of these proposals?

ZN (chat): https://webassembly.org/roadmap/

MD: wasmtime and nodejs ship SIMD under experimental flags

DG: for nodejs, they have a much other version of V8, usually 2 or 3 versions, may just be turned on by default when they use V8 9.1, trailing versions. Same for other proposals

AB: for wasmtime, the latest release should have SIMD turned on by default

JB: talked about it yesterday meeting, ARM support didn’t make latests release, want to do more vetting/testing before it was turned on by default

AB: Maybe the next release? That’s possible.

SR (chat): BTW I believe Node 16 ships SIMD (with v8 9.1)

SR (chat): and Node 16.6.0 is on v8 9.2

ZN: I don’t know how this roadmap is generated.

DG: can just file an issue, Ingvar can take care of this

ZN: MD want to talk about denormalied fp numbers control?

MD: participants should read offline and use comments

### SIMD instructions with multiple return values

MD: one thing about SIMD 2.0, multiple return values?

DG: possible, we shipped multiple returns. We didn’t want dependency between ongoing proposals, think we can do this. Will need a champion, and scoping this proposal.

MD: original SIMD proposal is pretty complete, but one area we can improve is to handle multiple values at once, e.g. extend mul of 2 vectors, produce both high and low, can be more efficient than current. Separate low and high part.

ZN: If we have multiple returns, what does it look like in the intrinsic functions?

MD: Neon has additional data types, Wasm intrinsics could also have v128x2 values

LH: looked at this in add with carry out, it becomes hairy because Wasm is a stack machine, you always get one result underneath and the other on top, sometimes that is a wrong order, so you have variants of instruction that produces results in one order or the other, to avoid moves. It’s not completely straightforward

ZN: We don’t have a swap, if we have that instruction, but maybe we could make it better?

LH: Not sure, but we definitely would need some experimentation.
