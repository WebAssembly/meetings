![WebAssembly logo](/images/WebAssembly.png)

## Agenda for the July 9th video call of WebAssembly's SIMD Subgroup

- **Dates**: 2021-07-09
- **Times**:
    - 4pm-5pm UTC (9am-10am PDT)
- **Location**: *link on calendar invite*

### Registration

You are a new attendee, please fill out this [form](https://forms.gle/9eB2ZYaziPEcTJabA) to attend.

## Agenda items

1. Opening, welcome and roll call
    1. Opening of the meeting
    1. Introduction of attendees
1. Find volunteers for note taking
1. Adoption of the agenda
1. Proposals and discussions
    1. Working on cost model (Petr Penzin)
    1. Relaxed simd update (Zhi An Ng)
1. Closure

## Meeting notes

### Attendees

- Evan Nemerson
- Yury Delendik
- Deepti Gandluri
- Petr Penzin
- Zhi An Ng
- Andrew Brown
- Rich Winterton
- Marat Dukhan
- Thomas Lively
- Johnnie Birch
- Jan Wassenberg

### Working on cost model (Petr Penzin)

PP: volunteer to work on cost model, wanted to make sure no conflict

TL: sg, haven’t worked on that, working on other isel stuff

Lowering data (Evan)

### Relaxed simd update (possible phase 2)

ZN: Before we go to phase 2 discussion, we need to decide if there are going to be any other classes of instructions we want to add to relaxed simd

MD: flushing of denormals, disable nan propagations, few ways to implement this. maybe function attributes? Function to get fpu state and function to restore fpu state, function to set.

ZN: For relaxed SIMD we decided to create a new instruction for each mode. Will this scale?

MD: Complicated to do this on the instruction level. In AVX 512 these are specified by setting state rather than as instructions. We could implement this with a function attribute, but there might be high overhead.

PP: Similar to the rounding mode discussions we had previously.

MD: this is not the same as rounding mode, Arm (?) does not support everything proposed there

PP: manipulating status word aspect is similar

JW: Clang reorders setting rounding mode

...

MD: the result is still valid, since it is non rounding mode, it will just be less performant

EN: sounds like a clang bug, seems like that should work, or at least file issue about it

JW: gcc knows about it since 10 years

EN: don’t think a lot of people use the functionality

PP: yea bug for sure, we’ve talked to different people, try to define new intrinsics… overall, fundamental with porting such things to wasm, global setting, you can inject code, everything will change, we don’t like such global settings

JW: can you flush normally? Is there one point they are created

MD: NaNs cann pop up anywhere

JW: subnormals flushing?

MD: can also be created, subtract 2 numbers of similar number and same sign. Subnormals guarantees if a != b, a - b != 0.

PP: you only want this on relaxed simd, not normal wasm level?

MD: will affect all of it

PP: maybe there is bringing this up separately

DG: some time around mvp where the fast mode was discussed in general, we decided to revisit this question when we add fma, kind of goes hand in hand. When I first imagined what relaxed simd is, it is a mode you can switch between, maps to fast mode flag. Imagine would hard to force just on SIMD and not on scalar operation.

RW: why is instruction set a hard blocker for phase 2? We were changing late in the game for SIMD.

DG: we need to solidify overall design of proposal

RW: was just thinking a fixed number of instructions

TL: even if just adding instructions, the whole proposal is adding instructions, consensus on design == consensus on instruction set. Good that we got implementer feedback, but the best process is to have consensus before moving ahead.

DG: we can agree which set of instructions we are adding, we can then add one or two to the set

PP: we were not adding non-det to SIMD, even though we were adding lots of new isntr

JB: relaxed-simd is attractive to me because as use cases become more known, particularly in standalone, the need for relaxing certain instructions before more prominent. As long as there is a path to add relaxed instructions.

PP: where do you stop?

MD: one aspect is, how restrictive should we be for values that can differ between implementations. Shouldn’t we be more restrictive, it’s an implementation defined function of input? Or enumerate which values are possible?

DG: won’t be opposed to be less restrictive to start with, then with implementor feedback to be more restrictive. A lot of the non-det is a function of the environment that we are building the proposals for. If browsers or engines don’t have a problem with it. Curious to know more about benefits of restriction?

MD: whether we want to support users testing for specific behavior or not. If instructions out of bounds is unspecified, it can be random, e.g. cann leave previous values. Users cannot really rely on testing with specific input, can be good or bad. It complicates implementation, there may be situations where users will care only about certain out of bounds results, and add special out of bounds results.

EN: if we make guarantees, we force implementations to use less optimal instruction since we already committed to a set of outputs

MD: realistic, we can see what arm/x86/powerpc output for particular inputs, make sure our specifications will be consistent. In the future, risc-v, unlikely to be influenced by Wasm SIMD.

DG: engines and implementations can specify limitations, e.g. memory limitations. Community agrees, but don’t need to spec it.

MD: in the end, users can look into source code, and how to lower. Better to provide guarantees that output is a deterministic function of input. E.g. float to int conversions, when input is NaN, below or above bounds. Can say the output in this case is some implementation defined constant.

TL: reminds me of fpenv, guarantee the output is a function of input, looks like the same fpenv thing this is trying to solve.

EN: implementations could also provide additional guarantees, if the spec says implementationn defined, implementation can define it, it’s whatever we want it to be, might change it. Mozilla can promise that on x86 we will always do that.

MD: will be hard to get all engines document what exactly they do. If you want to know, go read the source code.

TL: we can put it in the web embedding doc

DG: we can be more restrictive, concerned about having too many restrictions in the spec. Probably need more eyes on the issue

ZN: Marat, can you file an issue

MD: there are multiple different aspects here

ZN: at least one example can illustrate the problem

MD: I want instruction to flush denormals, not fast math flag. Global flag is the closest to how hardware does it. Function level is the closest, but my concern is that it won’t be easy to port existing code, also the overhead of function-level solution would be high and not acceptable to some users

ZN: function level flag can also interfere with optimizations

DG: flag mode is interesting in a way that it can help avoid opcode bloat

TL: Wasm is formalized, adding global flag complicates formalization. need to say what the benenfit of global state will be over adding instructions. Performancne cann be a compelling argument.

DG: can also make a code size argument. Can generate more opcodes up front, easier for engine, maybe code size v.s. Performance tradeoff

JB: is the implication that the global state each engine has to implement everything in relaxed simd.

JB: easier to reason about individual instructions giving non det, compared to global state

TL: yea definition, but also how much it matters

PP: discussion on other global state related things, setting this per-instruction (as opposed to global), it would make engines more complicated, as you can’t reset hardware mode per instruction, you would have to combine instructions with same mode somehow

RW: MD, do you see a use for CDT instructions?

MD: Yes, I use something similar in XNNPACK and it would be useful there.

RW: These seem to be in the same category as the relaxed instructions so far.

MD: I think there is already a proposal for these instructions. I32x4.trunc_sat… issue #21.

RW: That covers four formats, right?

MD: Yes. 64 or 32 bit, signed or unsigned.

EN: We already have two pairs of min/max instructions, but we don’t have a min/max where it may or may not be pmin/pmax.

MD: we shouldn’t result to just min/pmin

EN: seem to remember that i ran into situations where a platform didn’t support min or pmin, had something else

MD: risc-v doesn’t have min or pmin, in scalar instruction set, only minnum and maxnum

EN: will check, might be platforms where nans are handled differently.

MD: only need to check what powerpc does

DG: for previous SIMD proposal we were mostly keeping it focused on intel and arm, big portion of devices we were trying o address. What set of archs we want to target this proposal for?

EN: flexible-vectors proposal adds interesting element, a lot of 8-bit instructions missing in SSE, at least in SVE and AVX512. Even if they are only operating on 128-bit vectors, can use flexible vectors proposal, and keep relaxed limited to ARM and Intel.

MD: practically what we have today is intel arm and in theory powerpc. Everything that comes after that comes after that has to take into account Wasm SIMD itself.

EN: are we thinking we could add 8-bit shifts to relaxed SIMD, even though x86 doesn’t implement till AVX512.

MD: we have 8-bit shifts, cover intel arm powerpc well, don’t need cover something that is experimental.

EN: if x86 doesn’t cover it, leave it out of relaxed simd. Think there is less need for it in relaxed-simd if we have it in relaxed-simd specifications. If you want to use those instructions, you can use flexible-vectors.

MD: have to keep in mind the timeline, relaxed-simd is a small specification. We can get it out sooner. Flexible-simd is a huge specification, with large number of instructions, will take longer.

EN: makes sense. Right now people are on x86, and ARM. By the time that shifts, hopefully flexible will be closer.

MD: webgpu is supposed to get to be a real thing sometime in between, also will be less interest in using variable width simple once you have general purpose gpu.

PP: you can only use from JS.

MD: to sum up, i think relaxed-simd should target the case when we have Wasm SIMD and we don’t yet have flexible vectors. Since it’s bigger and will take longer to materialize.

PP: I don’t think webgpu is related at all.

MD: everything is driven by demand, need fast computation in browser, think webgpu will take away good portion of demand

PP: cant interface from within Wasm

DG: PP mentioned CPU workloads, some libraries use CPU workloads to not incur overhead of bringing up GPU, only useful for smaller workloads, interesting in flexible-vectors, think of useful workloads. A lot of proposals still early stage, interesting to see when flexible-vectors is more widely supported. Don’t have answer yet.

PP: do you know if anyone trying to interface with WebGPU from Wasm.

DG: no concrete proposal, some people thinking about how to solve this problem.
